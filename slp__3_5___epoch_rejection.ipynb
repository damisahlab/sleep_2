{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "\n",
    "import mne\n",
    "import yasa\n",
    "from scipy.stats import zscore\n",
    "import mne_features as mf\n",
    "from mne_features.feature_extraction import extract_features\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "\n",
    "from utils__helpers_macro import robust_zscore\n",
    "import utils__config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'g:\\\\My Drive\\\\Residency\\\\Research\\\\Lab - Damisah\\\\Project - Sleep'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(utils__config.working_directory)\n",
    "os.getcwd()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fif_path = 'Cache/Subject01/S01_Feb02_256hz.fif'\n",
    "potato_path = 'Cache/Subject01/S01_potatogram.csv'\n",
    "bad_epoch_path = 'Cache/Subject01/S01_bad_epochs.csv'\n",
    "bad_channel_path = 'Cache/Subject01/S01_bad_channels.csv'\n",
    "\n",
    "# fif_path = 'Cache/Subject02/Apr26/S02_Apr26_256hz.fif'\n",
    "# potato_path = 'Cache/Subject02/Apr26/S02_potatogram.csv'\n",
    "# bad_channel_path = 'Cache/Subject02/Apr26/S02_bad_channels.csv'\n",
    "# bad_epoch_path = 'Cache/Subject02/Apr26/S02_bad_epochs.csv'\n",
    "\n",
    "# fif_path = 'Cache/Subject02/Apr27/S02_Apr27_256hz.fif'\n",
    "# potato_path = 'Cache/Subject02/Apr27/S02_potatogram.csv'\n",
    "# bad_channel_path = 'Cache/Subject02/Apr27/S02_bad_channels.csv'\n",
    "# bad_epoch_path = 'Cache/Subject02/Apr27/S02_bad_epochs.csv'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please note that the number of samples must be whole-number divisible by (sampling_freq * epoch_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_freq = 256 # Hz\n",
    "epoch_length = 3 # seconds\n",
    "lof_threshold = -2\n",
    "chan_threshold = 3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Layton\\AppData\\Local\\Temp\\ipykernel_15220\\3029478263.py:1: RuntimeWarning: This filename (Cache/Subject01/S01_Feb02_256hz.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(fif_path, preload = True, verbose = False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channel count after bad channel removal: 68\n"
     ]
    }
   ],
   "source": [
    "raw = mne.io.read_raw_fif(fif_path, preload = True, verbose = False)\n",
    "\n",
    "# Select only macroelectrodes\n",
    "raw.pick_types(seeg = True, ecog = True)\n",
    "\n",
    "# Remove bad channels\n",
    "bad_channels = pd.read_csv(bad_channel_path)\n",
    "bad_channels = bad_channels[bad_channels['channel'].isin(raw.ch_names)]\n",
    "raw.drop_channels(ch_names = bad_channels['channel'].astype('string'))\n",
    "print('Channel count after bad channel removal:', len(raw.ch_names))\n",
    "\n",
    "# Load the upsampled hypnogram\n",
    "hypnogram = np.loadtxt(potato_path, delimiter = ',')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Epoch Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add hypnogram as a channel to the Raw object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating RawArray with float64 data, n_channels=1, n_times=1843574\n",
      "    Range : 0 ... 1843573 =      0.000 ...  7201.457 secs\n",
      "Ready.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"table table-hover table-striped table-sm table-responsive small\">\n",
       "    <tr>\n",
       "        <th>Measurement date</th>\n",
       "        \n",
       "        <td>February 02, 2022  05:41:39 GMT</td>\n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Experimenter</th>\n",
       "        \n",
       "        <td>Unknown</td>\n",
       "        \n",
       "    </tr>\n",
       "        <th>Participant</th>\n",
       "        \n",
       "        <td>Unknown</td>\n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Digitized points</th>\n",
       "        \n",
       "        <td>0 points</td>\n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Good channels</th>\n",
       "        <td>68 sEEG, 1 misc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Bad channels</th>\n",
       "        <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>EOG channels</th>\n",
       "        <td>Not available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>ECG channels</th>\n",
       "        <td>Not available</td>\n",
       "    \n",
       "    <tr>\n",
       "        <th>Sampling frequency</th>\n",
       "        <td>256.00 Hz</td>\n",
       "    </tr>\n",
       "    \n",
       "    \n",
       "    <tr>\n",
       "        <th>Highpass</th>\n",
       "        <td>0.00 Hz</td>\n",
       "    </tr>\n",
       "    \n",
       "    \n",
       "    <tr>\n",
       "        <th>Lowpass</th>\n",
       "        <td>128.00 Hz</td>\n",
       "    </tr>\n",
       "    \n",
       "    \n",
       "    \n",
       "    <tr>\n",
       "        <th>Filenames</th>\n",
       "        <td>S01_Feb02_256hz.fif</td>\n",
       "    </tr>\n",
       "    \n",
       "    <tr>\n",
       "        <th>Duration</th>\n",
       "        <td>02:00:01 (HH:MM:SS)</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Raw | S01_Feb02_256hz.fif, 69 x 1843574 (7201.5 s), ~970.6 MB, data loaded>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hypnogram dictionary: \n",
    "# (-2) = Unassigned\n",
    "# (-1) = Artifact\n",
    "# (0) = Awake\n",
    "# (1) = N1\n",
    "# (2) = N2\n",
    "# (3) = N3\n",
    "# (4) = REM \n",
    "\n",
    "# Re-value sleep stages for incorporation into Epochs object\n",
    "hypnogram[(hypnogram != 2) & (hypnogram != 3)] = 0\n",
    "hypnogram[(hypnogram == 2) | (hypnogram == 3)] = 1\n",
    "\n",
    "# Create raw object from the hypnogram\n",
    "hypnogram = hypnogram[np.newaxis, :]\n",
    "\n",
    "hypno_info = mne.create_info(ch_names = ['hypno'], \n",
    "                             sfreq = raw.info['sfreq'], \n",
    "                             ch_types = ['misc'])\n",
    "\n",
    "hypno = mne.io.RawArray(data = hypnogram,\n",
    "                        info = hypno_info,\n",
    "                        first_samp = raw.first_samp)\n",
    "\n",
    "raw.add_channels([hypno], force_update_info = True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create dummy stim data and an empty stim channel, then fill the channel with the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating RawArray with float64 data, n_channels=1, n_times=1843574\n",
      "    Range : 0 ... 1843573 =      0.000 ...  7201.457 secs\n",
      "Ready.\n"
     ]
    }
   ],
   "source": [
    "# Record the first sample (which is not 0 since the Raw\n",
    "# file was cropped from the original); you will need this\n",
    "# to appropriately select the epoch sample number\n",
    "start = raw.first_samp\n",
    "step = sampling_freq * epoch_length\n",
    "stop = raw.last_samp - step\n",
    "\n",
    "epoch_stim = np.arange(start, stop, step)\n",
    "\n",
    "# MNE Epochs expects a three column array where the second column\n",
    "# is a dummy spacer with 0's and the third is an integer indicating\n",
    "# the ID for the event. So we need to append these to our stim array.\n",
    "dummy_row = np.zeros(len(epoch_stim))\n",
    "event_row = np.ones(len(epoch_stim))\n",
    "\n",
    "epoch_stim = np.vstack((epoch_stim, dummy_row, event_row)).transpose()\n",
    "\n",
    "# Create a dummy numpy event array and MNE info object\n",
    "# and use them to create an empty dummy Raw channel\n",
    "events_info = mne.create_info(ch_names = ['epoch_stim'], \n",
    "                              sfreq = raw.info['sfreq'], \n",
    "                              ch_types = ['stim'])\n",
    "\n",
    "empty_events = np.zeros((1, len(raw.times)))\n",
    "\n",
    "events_channel = mne.io.RawArray(empty_events, events_info)\n",
    "\n",
    "# Create an event dictionary\n",
    "event_dictionary = {'epoch_start' : 1}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Epoch data using dummy stim data in the new channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2400 events found\n",
      "Event IDs: [1]\n",
      "Not setting metadata\n",
      "2400 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 2400 events and 769 original time points ...\n",
      "0 bad epochs dropped\n"
     ]
    }
   ],
   "source": [
    "# Update the empty stim channel with the formatted epoch start times\n",
    "raw.add_channels([events_channel], force_update_info = True)\n",
    "raw.add_events(epoch_stim, 'epoch_stim')\n",
    "\n",
    "# Find events and create epochs\n",
    "events = mne.find_events(raw, \n",
    "                         stim_channel = 'epoch_stim', \n",
    "                         shortest_event = sampling_freq * epoch_length,\n",
    "                         initial_event = True)\n",
    "\n",
    "epochs = mne.Epochs(raw, \n",
    "                    preload = True, \n",
    "                    events = events, \n",
    "                    event_id = event_dictionary, \n",
    "                    baseline = None,\n",
    "                    verbose = True,\n",
    "                    tmin = 0, \n",
    "                    tmax = epoch_length)\n",
    "\n",
    "# Drop the event channel before exporting data\n",
    "epochs = epochs.drop_channels(['epoch_stim'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select epochs with more than 50% N2/3 sleep and save their sample number start times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get epoched hypnogram and get SWS% per epoch\n",
    "hypochs = epochs.get_data(picks = ['hypno']).squeeze()\n",
    "hypochs = hypochs.mean(axis = 1).transpose()\n",
    "hypochs = pd.DataFrame(hypochs, columns = ['hypno_score'])\n",
    "\n",
    "# Keep epochs with more than 50% of SWS\n",
    "nopochs = pd.Series(hypochs[hypochs['hypno_score'] <= 0.50].index)\n",
    "hypochs = pd.Series(hypochs[hypochs['hypno_score'] > 0.50].index)\n",
    "\n",
    "# Remove hypno channel and get data\n",
    "epochs = epochs.drop_channels(['hypno'])\n",
    "data = epochs.get_data()\n",
    "\n",
    "# Delete non-SWS epochs\n",
    "data = np.delete(data, nopochs, axis = 0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract scalar features:\n",
    "# Input is (n_epochs, n_channels, n_times)\n",
    "# Output is (n_epochs, n_channels * n_features)\n",
    "mf_scalar = extract_features(data, \n",
    "                             sfreq = sampling_freq, \n",
    "                             selected_funcs = ['mean', 'variance', 'std', 'ptp_amp', \n",
    "                                               'skewness', 'kurtosis', 'rms', 'quantile', \n",
    "                                               'zero_crossings', 'hurst_exp'], \n",
    "                             ch_names = epochs.ch_names, \n",
    "                             return_as_df = True, \n",
    "                             n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract array features:\n",
    "# Output array of (n_epochs, n_channels * n_features)\n",
    "# but note that the second dimension will be a multi-index\n",
    "freq_bands = np.array([0.5, 4, 8, 13, 30, 50, 70, 100, sampling_freq/2])\n",
    "\n",
    "mf_params = {'pow_freq_bands__freq_bands' : freq_bands, \n",
    "             'spect_slope__fmin' : 0.3,\n",
    "             'spect_slope__fmax' : sampling_freq/2}\n",
    "\n",
    "mf_array = extract_features(data, \n",
    "                            sfreq = sampling_freq, \n",
    "                            selected_funcs = ['pow_freq_bands', 'spect_slope'], \n",
    "                            funcs_params = mf_params, \n",
    "                            ch_names = epochs.ch_names, \n",
    "                            return_as_df = True, \n",
    "                            n_jobs = -1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Munging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scalar features - Reshape multi-index to long\n",
    "mf_scalar = mf_scalar.unstack().reset_index()\n",
    "mf_scalar.columns = ['feature', 'channel', 'epoch', 'value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Array features - Reshape multi-index to long\n",
    "mf_array = mf_array.unstack().reset_index()\n",
    "mf_array.columns = ['long_feature', 'elec_feature', 'epoch', 'value']\n",
    "\n",
    "# Extract channel and feature names from the aggregate output column\n",
    "# (Note that channels with underscores in their name will break this)\n",
    "mf_array[['channel', 'feature']] = mf_array['elec_feature'].str.split('_', expand = True)\n",
    "\n",
    "# Convert to xarray\n",
    "mf_array = mf_array[['channel', 'epoch', 'feature', 'value']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append the scalar and array feature datasets:\n",
    "mf_feats = pd.concat([mf_scalar, mf_array])\n",
    "\n",
    "# Normalize features for comparability (robust z-score)\n",
    "#mf_feats['zscore'] = mf_feats.groupby(['feature'])['value'].transform(zscore)\n",
    "mf_feats['rzscore'] = mf_feats.groupby(['feature'])['value'].transform(robust_zscore)\n",
    "mf_feats.drop(columns = ['value'], inplace = True)\n",
    "\n",
    "# Convert to xarray\n",
    "mf_feats = mf_feats.set_index(['channel', 'epoch', 'feature'])\n",
    "mf_feats = mf_feats.to_xarray()\n",
    "\n",
    "# Save meta-data for later\n",
    "channels = mf_feats.channel.to_pandas()\n",
    "epochs = mf_feats.epoch.to_pandas()\n",
    "\n",
    "# Convert to numpy\n",
    "mf_feats = mf_feats.to_array().to_numpy().squeeze()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local Outlier Factor"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Channel-wise LOF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for channel in range(mf_feats.shape[0]):\n",
    "\n",
    "    chan_lof = LocalOutlierFactor()\n",
    "    _ = chan_lof.fit_predict(mf_feats[channel, :, :])\n",
    "    chan_lof = chan_lof.negative_outlier_factor_\n",
    "\n",
    "    if channel == 0:\n",
    "        lof = chan_lof[np.newaxis, :]\n",
    "\n",
    "    else:\n",
    "        lof = np.append(lof, chan_lof[np.newaxis, :], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert from wide to long format\n",
    "lof = pd.DataFrame(lof, index = channels, columns = epochs)\n",
    "lof = lof.reset_index()\n",
    "\n",
    "lof = lof.melt(id_vars = ['index'], var_name = 'epoch', value_name = 'lof')\n",
    "lof.columns = ['channel', 'epoch', 'lof']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rejection Thresholding"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Epoch rejection is all-or-none. An epoch must be deleted from all channels if it is rejected at all. Thus, if an epoch is selected as abnormal in more than N channels, the epoch times will be marked and saved to later remove any sleep events detected during those times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a table of channel counts with LOF < threshold for each epoch\n",
    "epoch_ct = lof[['epoch', 'lof']].loc[lof['lof'] < lof_threshold].groupby(['epoch']).count().reset_index()\n",
    "\n",
    "# Get epochs over the channel count threshold, these will be rejected\n",
    "below_lof = epoch_ct.loc[epoch_ct['lof'] > chan_threshold, 'epoch']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save rejected epochs for exclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get epoch sample numbers\n",
    "bad_epochs = pd.DataFrame(epoch_stim[:,0], columns = ['start'])\n",
    "bad_epochs['stop'] = bad_epochs['start'] + (sampling_freq * epoch_length)\n",
    "\n",
    "# Pad bad epochs by 1 second on either side, then\n",
    "# convert to int64 for use in indexing\n",
    "bad_epochs['start'] = bad_epochs['start'] - (sampling_freq * 1)\n",
    "bad_epochs['stop'] = bad_epochs['stop'] - (sampling_freq * 1)\n",
    "\n",
    "bad_epochs['start'] = bad_epochs['start'].astype('int64')\n",
    "bad_epochs['stop'] = bad_epochs['stop'].astype('int64')\n",
    "\n",
    "# Reset index to get the original hypnogram epoch index\n",
    "bad_epochs = bad_epochs.reset_index()\n",
    "bad_epochs.columns = ['hypno_epoch', 'start', 'stop']\n",
    "\n",
    "# Select only SWS epochs\n",
    "bad_epochs = bad_epochs[bad_epochs['hypno_epoch'].isin(hypochs)]\n",
    "\n",
    "# Reset index twice (after keeping only SWS epochs)\n",
    "# to get the equivalent LOF epoch index, which is\n",
    "# different from the hypno epoch since its a reset subset\n",
    "bad_epochs = bad_epochs.reset_index().reset_index()\n",
    "bad_epochs.columns = ['lof_epoch', 'dummy_epoch', 'hypno_epoch', 'start', 'stop']\n",
    "bad_epochs.drop(columns = ['dummy_epoch'], inplace = True)\n",
    "\n",
    "# Keep epochs that were selected by LOF as bad\n",
    "bad_epochs = bad_epochs[bad_epochs['lof_epoch'].isin(below_lof)]\n",
    "\n",
    "# # Create a zero-filled 1d array with length of\n",
    "# # total number of samples, and set value to 1\n",
    "# # at time points corresponding to the rejected\n",
    "# # epochs (with their padding added)\n",
    "# bad_segments = np.zeros(len(raw))\n",
    "\n",
    "# for index, row in bad_epochs.iterrows():\n",
    "#     bad_segments[row['start']:row['stop']] = 1\n",
    "\n",
    "# Convert sample numbers to seconds\n",
    "bad_epochs['start_time'] = (bad_epochs['start'] / sampling_freq) - (raw.first_samp / sampling_freq)\n",
    "bad_epochs['stop_time'] = (bad_epochs['stop'] / sampling_freq) - (raw.first_samp / sampling_freq)\n",
    "\n",
    "# Save to CSV\n",
    "bad_epochs.to_csv(bad_epoch_path, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lof_epoch</th>\n",
       "      <th>hypno_epoch</th>\n",
       "      <th>start</th>\n",
       "      <th>stop</th>\n",
       "      <th>start_time</th>\n",
       "      <th>stop_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>170</td>\n",
       "      <td>860</td>\n",
       "      <td>660224</td>\n",
       "      <td>660992</td>\n",
       "      <td>2579.0</td>\n",
       "      <td>2582.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>224</td>\n",
       "      <td>914</td>\n",
       "      <td>701696</td>\n",
       "      <td>702464</td>\n",
       "      <td>2741.0</td>\n",
       "      <td>2744.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>264</td>\n",
       "      <td>954</td>\n",
       "      <td>732416</td>\n",
       "      <td>733184</td>\n",
       "      <td>2861.0</td>\n",
       "      <td>2864.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>277</td>\n",
       "      <td>967</td>\n",
       "      <td>742400</td>\n",
       "      <td>743168</td>\n",
       "      <td>2900.0</td>\n",
       "      <td>2903.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>309</td>\n",
       "      <td>999</td>\n",
       "      <td>766976</td>\n",
       "      <td>767744</td>\n",
       "      <td>2996.0</td>\n",
       "      <td>2999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>318</td>\n",
       "      <td>1008</td>\n",
       "      <td>773888</td>\n",
       "      <td>774656</td>\n",
       "      <td>3023.0</td>\n",
       "      <td>3026.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>321</td>\n",
       "      <td>1011</td>\n",
       "      <td>776192</td>\n",
       "      <td>776960</td>\n",
       "      <td>3032.0</td>\n",
       "      <td>3035.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>398</td>\n",
       "      <td>1088</td>\n",
       "      <td>835328</td>\n",
       "      <td>836096</td>\n",
       "      <td>3263.0</td>\n",
       "      <td>3266.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>418</td>\n",
       "      <td>1108</td>\n",
       "      <td>850688</td>\n",
       "      <td>851456</td>\n",
       "      <td>3323.0</td>\n",
       "      <td>3326.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>486</td>\n",
       "      <td>1176</td>\n",
       "      <td>902912</td>\n",
       "      <td>903680</td>\n",
       "      <td>3527.0</td>\n",
       "      <td>3530.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1030</th>\n",
       "      <td>1030</td>\n",
       "      <td>1904</td>\n",
       "      <td>1462016</td>\n",
       "      <td>1462784</td>\n",
       "      <td>5711.0</td>\n",
       "      <td>5714.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1064</th>\n",
       "      <td>1064</td>\n",
       "      <td>2093</td>\n",
       "      <td>1607168</td>\n",
       "      <td>1607936</td>\n",
       "      <td>6278.0</td>\n",
       "      <td>6281.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1145</th>\n",
       "      <td>1145</td>\n",
       "      <td>2186</td>\n",
       "      <td>1678592</td>\n",
       "      <td>1679360</td>\n",
       "      <td>6557.0</td>\n",
       "      <td>6560.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1184</th>\n",
       "      <td>1184</td>\n",
       "      <td>2225</td>\n",
       "      <td>1708544</td>\n",
       "      <td>1709312</td>\n",
       "      <td>6674.0</td>\n",
       "      <td>6677.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1186</th>\n",
       "      <td>1186</td>\n",
       "      <td>2228</td>\n",
       "      <td>1710848</td>\n",
       "      <td>1711616</td>\n",
       "      <td>6683.0</td>\n",
       "      <td>6686.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1248</th>\n",
       "      <td>1248</td>\n",
       "      <td>2372</td>\n",
       "      <td>1821440</td>\n",
       "      <td>1822208</td>\n",
       "      <td>7115.0</td>\n",
       "      <td>7118.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      lof_epoch  hypno_epoch    start     stop  start_time  stop_time\n",
       "170         170          860   660224   660992      2579.0     2582.0\n",
       "224         224          914   701696   702464      2741.0     2744.0\n",
       "264         264          954   732416   733184      2861.0     2864.0\n",
       "277         277          967   742400   743168      2900.0     2903.0\n",
       "309         309          999   766976   767744      2996.0     2999.0\n",
       "318         318         1008   773888   774656      3023.0     3026.0\n",
       "321         321         1011   776192   776960      3032.0     3035.0\n",
       "398         398         1088   835328   836096      3263.0     3266.0\n",
       "418         418         1108   850688   851456      3323.0     3326.0\n",
       "486         486         1176   902912   903680      3527.0     3530.0\n",
       "1030       1030         1904  1462016  1462784      5711.0     5714.0\n",
       "1064       1064         2093  1607168  1607936      6278.0     6281.0\n",
       "1145       1145         2186  1678592  1679360      6557.0     6560.0\n",
       "1184       1184         2225  1708544  1709312      6674.0     6677.0\n",
       "1186       1186         2228  1710848  1711616      6683.0     6686.0\n",
       "1248       1248         2372  1821440  1822208      7115.0     7118.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_epochs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sandbox",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
