{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "\n",
    "import mne\n",
    "import yasa\n",
    "from scipy.stats import zscore\n",
    "import plotnine as pn\n",
    "\n",
    "from utils__helpers_macro import robust_zscore, welch_psd\n",
    "import utils__config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Z:\\\\Layton\\\\Sleep_083023'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(utils__config.working_directory)\n",
    "os.getcwd()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fif_path = 'Data/S01_Feb02_micro_1024hz.fif'\n",
    "# potato_path = 'Data/S01_Feb02_potatogram.csv'\n",
    "# dict_path = 'Data/S01_dictionary.xlsx'\n",
    "# psd_out_path = 'Results/S01_Feb02_micro_psd.svg'\n",
    "\n",
    "# fif_path = 'Data/S05_Jul11_micro_1024hz.fif'\n",
    "# potato_path = 'Data/S05_Jul11_potatogram.csv'\n",
    "# dict_path = 'Data/S05_dictionary.xlsx'\n",
    "# psd_out_path = 'Results/S05_Jul11_micro_psd.svg'\n",
    "\n",
    "# fif_path = 'Data/S05_Jul12_micro_1024hz.fif'\n",
    "# potato_path = 'Data/S05_Jul12_potatogram.csv'\n",
    "# dict_path = 'Data/S05_dictionary.xlsx'\n",
    "# psd_out_path = 'Results/S05_Jul12_micro_psd.svg'\n",
    "\n",
    "fif_path = 'Data/S05_Jul13_micro_1024hz.fif'\n",
    "potato_path = 'Data/S05_Jul13_potatogram.csv'\n",
    "dict_path = 'Data/S05_dictionary.xlsx'\n",
    "psd_out_path = 'Results/S05_Jul13_micro_psd.svg'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please note that the number of samples must be whole-number divisible by (sampling_freq * epoch_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_regions = ['CLA', 'ACC', 'AMY']\n",
    "sampling_freq = 1024 # Hz\n",
    "epoch_length = 30 # seconds"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Epoch Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lal85\\AppData\\Local\\Temp\\2\\ipykernel_20372\\200238328.py:2: RuntimeWarning: This filename (Cache/Subject05/Jul11/S05_Jul11_micro_1024hz.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating RawArray with float64 data, n_channels=1, n_times=35686400\n",
      "    Range : 0 ... 35686399 =      0.000 ... 139399.996 secs\n",
      "Ready.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"table table-hover table-striped table-sm table-responsive small\">\n",
       "    <tr>\n",
       "        <th>Measurement date</th>\n",
       "        \n",
       "        <td>July 12, 2023  01:35:18 GMT</td>\n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Experimenter</th>\n",
       "        \n",
       "        <td>Unknown</td>\n",
       "        \n",
       "    </tr>\n",
       "        <th>Participant</th>\n",
       "        \n",
       "        <td>Unknown</td>\n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Digitized points</th>\n",
       "        \n",
       "        <td>0 points</td>\n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Good channels</th>\n",
       "        <td>64 sEEG, 1 misc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Bad channels</th>\n",
       "        <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>EOG channels</th>\n",
       "        <td>Not available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>ECG channels</th>\n",
       "        <td>Not available</td>\n",
       "    \n",
       "    <tr>\n",
       "        <th>Sampling frequency</th>\n",
       "        <td>1024.00 Hz</td>\n",
       "    </tr>\n",
       "    \n",
       "    \n",
       "    <tr>\n",
       "        <th>Highpass</th>\n",
       "        <td>0.30 Hz</td>\n",
       "    </tr>\n",
       "    \n",
       "    \n",
       "    <tr>\n",
       "        <th>Lowpass</th>\n",
       "        <td>256.00 Hz</td>\n",
       "    </tr>\n",
       "    \n",
       "    \n",
       "    \n",
       "    <tr>\n",
       "        <th>Filenames</th>\n",
       "        <td>S05_Jul11_micro_1024hz.fif&lt;br&gt;S05_Jul11_micro_1024hz-1.fif&lt;br&gt;S05_Jul11_micro_1024hz-2.fif&lt;br&gt;S05_Jul11_micro_1024hz-3.fif&lt;br&gt;S05_Jul11_micro_1024hz-4.fif</td>\n",
       "    </tr>\n",
       "    \n",
       "    <tr>\n",
       "        <th>Duration</th>\n",
       "        <td>09:40:50 (HH:MM:SS)</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Raw | S05_Jul11_micro_1024hz.fif, 65 x 35686400 (34850.0 s), ~17.28 GB, data loaded>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the micro data\n",
    "raw = mne.io.read_raw_fif(fif_path, preload = True, verbose = False)\n",
    "\n",
    "# Load the upsampled hypnogram\n",
    "hypnogram = np.loadtxt(potato_path, delimiter = ',')\n",
    "\n",
    "# Add hypnogram as a channel to the Raw object\n",
    "\n",
    "# Hypnogram dictionary: \n",
    "# (-2) = Unassigned\n",
    "# (-1) = Artifact\n",
    "# (0) = Awake\n",
    "# (1) = N1\n",
    "# (2) = N2\n",
    "# (3) = N3\n",
    "# (4) = REM \n",
    "\n",
    "# Re-value sleep stages for incorporation into Epochs object\n",
    "hypnogram[(hypnogram != 1) & (hypnogram != 2) & (hypnogram != 3)] = 0\n",
    "hypnogram[(hypnogram == 1) | (hypnogram == 2) | (hypnogram == 3)] = 1\n",
    "\n",
    "# Upsample to 1024 Hz from 256 Hz for compatibility\n",
    "hypnogram = yasa.hypno_upsample_to_data(hypno = hypnogram,\n",
    "                                        sf_hypno = 256,\n",
    "                                        data = raw)\n",
    "\n",
    "# Create raw object from the hypnogram\n",
    "hypnogram = hypnogram[np.newaxis, :]\n",
    "\n",
    "hypno_info = mne.create_info(ch_names = ['hypno'], \n",
    "                             sfreq = raw.info['sfreq'] / 4, \n",
    "                             ch_types = ['misc'])\n",
    "\n",
    "hypno = mne.io.RawArray(data = hypnogram,\n",
    "                        info = hypno_info,\n",
    "                        first_samp = raw.first_samp)\n",
    "\n",
    "raw.add_channels([hypno], force_update_info = True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create dummy stim data and an empty stim channel, then fill the channel with the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating RawArray with float64 data, n_channels=1, n_times=35686400\n",
      "    Range : 0 ... 35686399 =      0.000 ... 34849.999 secs\n",
      "Ready.\n"
     ]
    }
   ],
   "source": [
    "# Record the first sample (which is not 0 since the Raw\n",
    "# file was cropped from the original); you will need this\n",
    "# to appropriately select the epoch sample number\n",
    "start = raw.first_samp\n",
    "step = sampling_freq * epoch_length\n",
    "stop = raw.last_samp - step\n",
    "\n",
    "epoch_stim = np.arange(start, stop, step)\n",
    "\n",
    "# MNE Epochs expects a three column array where the second column\n",
    "# is a dummy spacer with 0's and the third is an integer indicating\n",
    "# the ID for the event. So we need to append these to our stim array.\n",
    "dummy_row = np.zeros(len(epoch_stim))\n",
    "event_row = np.ones(len(epoch_stim))\n",
    "\n",
    "epoch_stim = np.vstack((epoch_stim, dummy_row, event_row)).transpose()\n",
    "\n",
    "# Create a dummy numpy event array and MNE info object\n",
    "# and use them to create an empty dummy Raw channel\n",
    "events_info = mne.create_info(ch_names = ['epoch_stim'], \n",
    "                              sfreq = raw.info['sfreq'], \n",
    "                              ch_types = ['stim'])\n",
    "\n",
    "empty_events = np.zeros((1, len(raw.times)))\n",
    "\n",
    "events_channel = mne.io.RawArray(empty_events, events_info)\n",
    "\n",
    "# Create an event dictionary\n",
    "event_dictionary = {'epoch_start' : 1}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Epoch data using dummy stim data in the new channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1161 events found\n",
      "Event IDs: [1]\n",
      "Not setting metadata\n",
      "1161 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 1161 events and 30721 original time points ...\n",
      "0 bad epochs dropped\n"
     ]
    }
   ],
   "source": [
    "# Update the empty stim channel with the formatted epoch start times\n",
    "raw.add_channels([events_channel], force_update_info = True)\n",
    "raw.add_events(epoch_stim, 'epoch_stim')\n",
    "\n",
    "# Find events and create epochs\n",
    "events = mne.find_events(raw, \n",
    "                         stim_channel = 'epoch_stim', \n",
    "                         shortest_event = sampling_freq * epoch_length,\n",
    "                         initial_event = True)\n",
    "\n",
    "epochs = mne.Epochs(raw, \n",
    "                    preload = True, \n",
    "                    events = events, \n",
    "                    event_id = event_dictionary, \n",
    "                    baseline = None,\n",
    "                    verbose = True,\n",
    "                    tmin = 0, \n",
    "                    tmax = epoch_length)\n",
    "\n",
    "# Drop the event channel before exporting data\n",
    "epochs = epochs.drop_channels(['epoch_stim'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select epochs with more than 50% N2/3 sleep and save their sample number start times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get epoched hypnogram and get SWS% per epoch\n",
    "hypochs = epochs.get_data(picks = ['hypno']).squeeze()\n",
    "hypochs = hypochs.mean(axis = 1).transpose()\n",
    "hypochs = pd.DataFrame(hypochs, columns = ['hypno_score'])\n",
    "\n",
    "# Keep epochs with more than 50% of SWS\n",
    "nopochs = pd.Series(hypochs[hypochs['hypno_score'] <= 0.50].index)\n",
    "hypochs = pd.Series(hypochs[hypochs['hypno_score'] > 0.50].index)\n",
    "\n",
    "# Remove hypno channel and get data\n",
    "epochs = epochs.drop_channels(['hypno'])\n",
    "\n",
    "# N2/3 sleep\n",
    "nosleep = epochs[nopochs.tolist()]\n",
    "nosleep = nosleep.get_data(units = 'uV').transpose(1, 0, 2).reshape(len(epochs.ch_names), -1)\n",
    "\n",
    "# Non-N2/3 sleep\n",
    "sleep = epochs[hypochs.tolist()]\n",
    "sleep = sleep.get_data(units = 'uV').transpose(1, 0, 2).reshape(len(epochs.ch_names), -1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Welch PSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effective window size : 0.250 (s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   4 | elapsed:   11.2s remaining:   11.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effective window size : 0.250 (s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:   14.1s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   4 | elapsed:   11.6s remaining:   11.6s\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:   14.7s finished\n"
     ]
    }
   ],
   "source": [
    "# Welch PSD\n",
    "tfr_sleep = welch_psd(data = sleep, chan_names = epochs.ch_names, sampling_freq = sampling_freq, freq_min = 0.3, freq_max = 200, n_jobs = 4)\n",
    "tfr_nosleep = welch_psd(data = nosleep, chan_names = epochs.ch_names, sampling_freq = sampling_freq, freq_min = 0.3, freq_max = 200, n_jobs = 4)\n",
    "\n",
    "# Average PSD across channels\n",
    "#tfr_sleep = tfr_sleep.groupby('frequency').mean('log_power').reset_index()\n",
    "#tfr_nosleep = tfr_nosleep.groupby('frequency').mean('log_power').reset_index()\n",
    "\n",
    "# Add sleep stage column\n",
    "tfr_sleep['stage'] = 'NREM'\n",
    "tfr_nosleep['stage'] = 'W/REM'\n",
    "\n",
    "# Merge sleep/nosleep tfr's\n",
    "tfr = pd.concat([tfr_sleep, tfr_nosleep])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ch_dict = pd.read_excel(dict_path)\n",
    "\n",
    "# Extract the channel numbers and create a new column 'number'\n",
    "tfr['number'] = tfr['channel'].str.extract('(\\d+)').astype(int)\n",
    "\n",
    "# Merge with channel dictionary\n",
    "tfr = pd.merge(tfr, ch_dict, on='number', how='left')\n",
    "\n",
    "# Select only relevant micro regions\n",
    "tfr = tfr[tfr['region'].isin(selected_regions)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a color mapping for regions\n",
    "# region_colors = {\n",
    "#     'CLA': '#E28DB8',\n",
    "#     'ACC': '#A67A77',\n",
    "#     'AMY': '#7BA387'\n",
    "# }\n",
    "\n",
    "# # Map the region colors to the channels\n",
    "# tfr['facet_color'] = tfr['region'].map(region_colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lal85\\AppData\\Local\\miniconda3\\envs\\boss\\Lib\\site-packages\\plotnine\\ggplot.py:587: PlotnineWarning: Saving 20 x 15 in image.\n",
      "c:\\Users\\lal85\\AppData\\Local\\miniconda3\\envs\\boss\\Lib\\site-packages\\plotnine\\ggplot.py:588: PlotnineWarning: Filename: Results/S05_Jul11_micro_psd_HFA.svg\n"
     ]
    }
   ],
   "source": [
    "# Static plot with Plotnine\n",
    "p = (pn.ggplot(tfr)\n",
    " + pn.aes(x='frequency', y='log_power', color='stage')\n",
    " + pn.scale_fill_identity()  # Use actual color values in 'fill' column\n",
    " + pn.geom_line()\n",
    " + pn.facet_wrap('~ channel + region')\n",
    " + pn.scale_x_continuous(expand=(0, 0), limits=(1, 200))\n",
    " + pn.labs(x='Frequency (Hz)', y='Log Power (dB)')\n",
    " + pn.theme_classic()\n",
    " + pn.theme(figure_size=(20, 15), panel_border=pn.element_rect(color='black', size=1))\n",
    ")\n",
    "\n",
    "# Save the plot\n",
    "p.save(filename=psd_out_path, dpi=300)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sandbox",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
