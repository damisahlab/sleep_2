{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "import mne\n",
    "from scipy.stats import zscore\n",
    "from tqdm import tqdm\n",
    "\n",
    "from utils__helpers_macro import hilbert_powerphase, hilbert_envelope\n",
    "from utils__helpers_epoch import epoch_sw, epoch_sw_2, epoch_spikes\n",
    "import utils__config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'g:\\\\My Drive\\\\Residency\\\\Research\\\\Lab - Damisah\\\\Project - Sleep'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(utils__config.working_directory)\n",
    "os.getcwd()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will need to run this script once for **1s epochs** and once for **10s epochs.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fif_path = 'Cache/Subject01/S01_Feb02_256hz.fif'\n",
    "bad_channel_path = 'Cache/Subject01/S01_bad_channels.csv'\n",
    "hypno_path = 'Cache/Subject01/S01_hypnogram.csv' \n",
    "sw_path = 'Cache/Subject01/S01_SW.csv'\n",
    "spike_path = 'Cache/Subject01/S01_spikes.csv'\n",
    "sw_out_path = 'Cache/Subject01/S01_sw_epochs_30s.csv'\n",
    "spike_out_path = 'Cache/Subject01/S01_spike_epochs_30s.csv'\n",
    "hypno_out_path = 'Cache/Subject01/S01_hypno_epochs_30s.csv' \n",
    "\n",
    "# fif_path = 'Cache/Subject02/Apr26/S02_Apr26_256hz.fif'\n",
    "# bad_channel_path = 'Cache/Subject02/Apr26/S02_Apr26_bad_channels.csv'\n",
    "# hypno_path = 'Cache/Subject02/Apr26/S02_Apr26_hypnogram.csv' \n",
    "# sw_path = 'Cache/Subject02/Apr26/S02_Apr26_SW.csv'\n",
    "# spike_path = 'Cache/Subject02/Apr26/S02_spikes.csv'\n",
    "# sw_out_path = 'Cache/Subject02/Apr26/S02_sw_epochs_30s.csv'\n",
    "# spike_out_path = 'Cache/Subject02/Apr26/S02_spike_epochs_30s.csv'\n",
    "# hypno_out_path = 'Cache/Subject02/Apr26/S02_hypno_epochs_30s.csv' \n",
    "\n",
    "# fif_path = 'Cache/Subject02/Apr27/S02_Apr27_256hz.fif'\n",
    "# bad_channel_path = 'Cache/Subject02/Apr27/S02_bad_channels.csv'\n",
    "# hypno_path = 'Cache/Subject02/Apr27/S02_hypnogram.csv' \n",
    "# sw_path = 'Cache/Subject02/Apr27/S02_SW.csv'\n",
    "# spike_path = 'Cache/Subject02/Apr27/S02_spikes.csv'\n",
    "# sw_out_path = 'Cache/Subject02/Apr27/S02_sw_epochs_10s.csv'\n",
    "# spike_out_path = 'Cache/Subject02/Apr27/S02_spike_epochs_10s.csv'\n",
    "# hypno_out_path = 'Cache/Subject02/Apr27/S02_hypno_epochs_10s.csv' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_length = 30 # bin width in seconds\n",
    "sw_merge_threshold = 1 # how close SW's need to be for merging (in seconds)\n",
    "sampling_freq = 256 # (s.f. used to detect slow waves)\n",
    "hypno_sfreq = 256 # (s.f. used to make hypnogram)\n",
    "tmin = 'none' # datetime.datetime(2022, 4, 28, 0, 0, 0, 0, tzinfo = datetime.timezone.utc)\n",
    "tmax = 'none'\n",
    "n_jobs = -2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file Cache/Subject01/S01_Feb02_256hz.fif...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\layto\\AppData\\Local\\Temp\\ipykernel_34564\\580800819.py:1: RuntimeWarning: This filename (Cache/Subject01/S01_Feb02_256hz.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(fif_path, preload = True, verbose = None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Isotrak not found\n",
      "    Range : 0 ... 1843573 =      0.000 ...  7201.457 secs\n",
      "Ready.\n",
      "Reading 0 ... 1843573  =      0.000 ...  7201.457 secs...\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    }
   ],
   "source": [
    "raw = mne.io.read_raw_fif(fif_path, preload = True, verbose = None)\n",
    "\n",
    "# Select only macroelectrodes\n",
    "raw.pick_types(seeg = True, ecog = True)\n",
    "\n",
    "# Remove rejected channels\n",
    "bad_channels = pd.read_csv(bad_channel_path)\n",
    "bad_channels = bad_channels[bad_channels['channel'].isin(raw.ch_names)]\n",
    "raw.drop_channels(ch_names = bad_channels['channel'].astype('string'))\n",
    "\n",
    "# Set the bin size; we set the stop interval\n",
    "# to the total length of the recording\n",
    "if tmin != 'none':\n",
    "\n",
    "    last_bin = int((tmax - tmin).seconds / epoch_length) # will use this later\n",
    "    bin_list = np.arange(0, (tmax - tmin).seconds + 1, epoch_length)\n",
    "\n",
    "# Define tmin/tmax as the start/end of recording if not specified\n",
    "else:\n",
    "    \n",
    "    tmin = raw.times[0]\n",
    "    tmax = raw.times[-1]\n",
    "\n",
    "    last_bin = int((tmax - tmin) / epoch_length) # will use this later\n",
    "    bin_list = np.arange(0, (tmax - tmin) + 1, epoch_length)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bin Hypnogram into Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypno = pd.read_csv(hypno_path, header = None)\n",
    "hypno = hypno.reset_index()\n",
    "hypno.columns = ['idx', 'stage']\n",
    "\n",
    "# Bin the hypnogram into epochs based on sample number\n",
    "hypno['epoch'] = pd.cut(hypno['idx'], bins = bin_list * hypno_sfreq, labels = False, include_lowest = True)\n",
    "\n",
    "# Select the mode of the sleep stage within each epoch\n",
    "hypno = hypno.groupby(['epoch'])['stage'].agg(pd.Series.mode).reset_index()\n",
    "\n",
    "hypno.to_csv(hypno_out_path, index = False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bin Delta Power into average per Epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.3 - 4 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.30\n",
      "- Lower transition bandwidth: 0.30 Hz (-6 dB cutoff frequency: 0.15 Hz)\n",
      "- Upper passband edge: 4.00 Hz\n",
      "- Upper transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 5.00 Hz)\n",
      "- Filter length: 2817 samples (11.004 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-2)]: Using backend LokyBackend with 31 concurrent workers.\n",
      "[Parallel(n_jobs=-2)]: Done  52 out of  68 | elapsed:    3.7s remaining:    1.1s\n",
      "[Parallel(n_jobs=-2)]: Done  66 out of  68 | elapsed:    3.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=-2)]: Done  68 out of  68 | elapsed:    3.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting \"channel\" to \"category\"...\n",
      "Converting \"ch_type\" to \"category\"...\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.3 - 4 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.30\n",
      "- Lower transition bandwidth: 0.30 Hz (-6 dB cutoff frequency: 0.15 Hz)\n",
      "- Upper passband edge: 4.00 Hz\n",
      "- Upper transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 5.00 Hz)\n",
      "- Filter length: 2817 samples (11.004 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-2)]: Using backend LokyBackend with 31 concurrent workers.\n",
      "[Parallel(n_jobs=-2)]: Done  52 out of  68 | elapsed:    1.4s remaining:    0.4s\n",
      "[Parallel(n_jobs=-2)]: Done  66 out of  68 | elapsed:    1.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=-2)]: Done  68 out of  68 | elapsed:    1.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting \"channel\" to \"category\"...\n",
      "Converting \"ch_type\" to \"category\"...\n"
     ]
    }
   ],
   "source": [
    "# Extract Power and Phase\n",
    "delta = raw.copy()\n",
    "delta = hilbert_powerphase(data = delta, lower = 0.3, upper = 4, njobs = n_jobs)\n",
    "delta = delta[['time', 'channel', 'power']]\n",
    "\n",
    "# Calculate z-score of power \n",
    "delta['log_power'] = 10 * np.log10(delta['power'])\n",
    "delta['zlog_power'] = delta.groupby(['channel'])['log_power'].transform(zscore)\n",
    "\n",
    "# Extract Envelope\n",
    "delta_env = raw.copy()\n",
    "delta_env = hilbert_envelope(data = delta_env, lower = 0.3, upper = 4, njobs = n_jobs)\n",
    "delta_env = delta_env[['time', 'channel', 'envelope']]\n",
    "\n",
    "# Calculate z-score of envelope\n",
    "delta_env['z_envelope'] = delta_env.groupby(['channel'])['envelope'].transform(zscore)\n",
    "\n",
    "# Combine Power/Phase and Envelope\n",
    "delta = delta.merge(delta_env, on = ['time', 'channel'])\n",
    "\n",
    "# Bin the data with integer bin labels (pandas.cut \n",
    "# by default will create bins open on the left)\n",
    "delta['epoch'] = pd.cut(delta['time'], bins = bin_list, labels = False)\n",
    "\n",
    "# Average delta power by Epoch\n",
    "delta = delta.groupby(['epoch', 'channel'])[['log_power', 'zlog_power', 'envelope', 'z_envelope']].mean().round(2).reset_index()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bin Beta Power into average per Epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 15 - 30 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 15.00\n",
      "- Lower transition bandwidth: 3.75 Hz (-6 dB cutoff frequency: 13.12 Hz)\n",
      "- Upper passband edge: 30.00 Hz\n",
      "- Upper transition bandwidth: 7.50 Hz (-6 dB cutoff frequency: 33.75 Hz)\n",
      "- Filter length: 227 samples (0.887 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-2)]: Using backend LokyBackend with 31 concurrent workers.\n",
      "[Parallel(n_jobs=-2)]: Done  52 out of  68 | elapsed:    1.4s remaining:    0.4s\n",
      "[Parallel(n_jobs=-2)]: Done  66 out of  68 | elapsed:    1.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=-2)]: Done  68 out of  68 | elapsed:    1.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting \"channel\" to \"category\"...\n",
      "Converting \"ch_type\" to \"category\"...\n"
     ]
    }
   ],
   "source": [
    "# Extract Power and Phase\n",
    "beta = raw.copy()\n",
    "beta = hilbert_powerphase(data = beta, lower = 15, upper = 30, njobs = n_jobs)\n",
    "beta = beta[['time', 'channel', 'power']]\n",
    "\n",
    "# Calculate z-score of power and envelope\n",
    "beta['beta_log_power'] = 10 * np.log10(beta['power'])\n",
    "beta['beta_zlog_power'] = beta.groupby(['channel'])['beta_log_power'].transform(zscore)\n",
    "\n",
    "# Bin the data with integer bin labels (pandas.cut \n",
    "# by default will create bins open on the left)\n",
    "beta['epoch'] = pd.cut(beta['time'], bins = bin_list, labels = False)\n",
    "\n",
    "# Average beta power by Epoch\n",
    "beta = beta.groupby(['epoch', 'channel'])[['beta_log_power', 'beta_zlog_power']].mean().round(2).reset_index()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bin SW's into duration per Epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34/34 [00:02<00:00, 12.43it/s]\n"
     ]
    }
   ],
   "source": [
    "sw = epoch_sw_2(sw_path = sw_path, \n",
    "                tmin = tmin, \n",
    "                tmax = tmax, \n",
    "                merge_threshold = sw_merge_threshold, \n",
    "                sampling_freq = sampling_freq, \n",
    "                bin_list = bin_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the Delta Power, Beta Power, and Slow Wave Duration data\n",
    "sw_delta = delta.merge(sw, on = ['epoch', 'channel'])\n",
    "sw_delta = sw_delta.merge(beta, on = ['epoch', 'channel'])\n",
    "\n",
    "sw_delta.to_csv(sw_out_path, index = False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bin spikes into FR per Epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "spikes = epoch_spikes(spike_path = spike_path, \n",
    "                      bin_width = epoch_length, \n",
    "                      bin_list = bin_list, \n",
    "                      last_bin = last_bin)\n",
    "\n",
    "spikes.to_csv(spike_out_path, index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sandbox",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bceaa3bdda3825794b37c15d2000316b6f4a45a3d4f5e14660beed4f1d5f7638"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
