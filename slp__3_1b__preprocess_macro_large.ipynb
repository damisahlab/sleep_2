{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script (Version B) is designed to pre-process a folder of `.mat` v7.3 files that contains one channel each. This is optimal for very large recordings that would otherwise max out RAM if processed as a single file. Please note that comments have largely been removed from this version; please see Version A for full commentary."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import mne\n",
    "\n",
    "from tqdm import tqdm\n",
    "import datetime\n",
    "import hdf5storage\n",
    "import collections as cl\n",
    "\n",
    "import utils__config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'g:\\\\My Drive\\\\Residency\\\\Research\\\\Lab - Damisah\\\\Project - Sleep'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(utils__config.working_directory)\n",
    "os.getcwd()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = 'Cache/Subject02/Apr26/Macro_Apr26'\n",
    "dictionary_path = 'Data/Subject02/S02_dictionary.xlsx'\n",
    "legui_path = 'Cache/Subject02/S02_electrodes.csv'\n",
    "save_path = 'Cache/Subject02/Apr26/S02_Apr26_256hz.fif'\n",
    "\n",
    "# dir_path = 'Cache/Subject02/Apr27/Macro_Apr27'\n",
    "# dictionary_path = 'Data/Subject02/S02_dictionary.xlsx'\n",
    "# legui_path = 'Cache/Subject02/S02_electrodes.csv'\n",
    "# save_path = 'Cache/Subject02/Apr27/S02_Apr27_256hz.fif'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_freq = 256"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert MAT to MNE Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ch_dictionary = pd.read_excel(dictionary_path)\n",
    "\n",
    "channel_map = {'macro' : 'seeg',\n",
    "               'scalp' : 'eeg',\n",
    "               'ecg' : 'ecg',\n",
    "               'emg' : 'emg',\n",
    "               'eog' : 'eog',\n",
    "               'micro' : 'misc',\n",
    "               'ttl' : 'stim',\n",
    "               'vitals' : 'bio',\n",
    "               'empty' : 'misc'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating RawArray with float64 data, n_channels=1, n_times=86400001\n",
      "    Range : 0 ... 86400000 =      0.000 ... 43200.000 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=1, n_times=86400001\n",
      "    Range : 0 ... 86400000 =      0.000 ... 43200.000 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=1, n_times=86400001\n",
      "    Range : 0 ... 86400000 =      0.000 ... 43200.000 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=1, n_times=86400001\n",
      "    Range : 0 ... 86400000 =      0.000 ... 43200.000 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=1, n_times=86400001\n",
      "    Range : 0 ... 86400000 =      0.000 ... 43200.000 secs\n",
      "Ready.\n"
     ]
    }
   ],
   "source": [
    "for channel in tqdm(os.listdir(dir_path)):\n",
    "\n",
    "    # Load Data\n",
    "    file_path = os.path.join(dir_path, channel)\n",
    "    data = hdf5storage.loadmat(file_path)\n",
    "\n",
    "    # Convert V to uV\n",
    "    time_series = data['time_series'] * 1e-6\n",
    "\n",
    "    # Channel Name\n",
    "    ch_num = int(channel.split('_')[1].split('.')[0].split('Channel')[1])\n",
    "    ch_name = ch_dictionary.loc[ch_dictionary['number'] == ch_num, 'name'].tolist()\n",
    "\n",
    "    # Channel Type\n",
    "    ch_type = ch_dictionary.loc[ch_dictionary['number'] == ch_num, 'type'].tolist()[0]\n",
    "    ch_type = channel_map[ch_type]\n",
    "\n",
    "    # Sampling Frequency\n",
    "    sfreq = data['meta_data']['sampling_rate'].astype(np.int64)[0][0][0]\n",
    "\n",
    "    # Start Time\n",
    "    raw_time = data['meta_data']['time_stamp'][0][0][0][0].astype(np.int64)\n",
    "    time_start = datetime.datetime(raw_time[0], raw_time[1], raw_time[3], \n",
    "                                   raw_time[4], raw_time[5], raw_time[6], \n",
    "                                   raw_time[7], tzinfo = datetime.timezone.utc)\n",
    "\n",
    "    # Create Raw object\n",
    "    info = mne.create_info(ch_names = ch_name,\n",
    "                           sfreq = sfreq,\n",
    "                           ch_types = ch_type)\n",
    "\n",
    "    single_raw = mne.io.RawArray(data = time_series,\n",
    "                          info = info)\n",
    "\n",
    "    single_raw.set_meas_date(time_start)\n",
    "\n",
    "    # Crop start and stop times (optional)\n",
    "    if ('tmin' in locals() or 'tmin' in globals()):\n",
    "        tmin = (tmin - time_start).total_seconds()\n",
    "        tmax = (tmax - time_start).total_seconds()\n",
    "        single_raw.crop(tmin = tmin, tmax = tmax)\n",
    "\n",
    "    # Decimate (automatic bandpass to Nyquist frequency)\n",
    "    single_raw.resample(sfreq = sampling_freq)\n",
    "\n",
    "    # Concatenate channels\n",
    "    if ('raw' in locals() or 'raw' in globals()):\n",
    "        raw.add_channels([single_raw])\n",
    "\n",
    "    else:\n",
    "        raw = single_raw.copy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Bandpass filter \n",
    "# (Note that the .NS3 files already had\n",
    "#  an 0.3 - 500 Hz filter applied at \n",
    "#  the hardware level)\n",
    "#raw.filter(l_freq = None, h_freq = 60, n_jobs = -1)\n",
    "\n",
    "# Notch filter to remove 60 Hz line noise\n",
    "raw.notch_filter(np.arange(60, sampling_freq/2, 60))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re-reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-reference macro electrodes to macro-CAR\n",
    "macro_ref = ch_dictionary[ch_dictionary['type'] == 'macro']['name'].to_list()\n",
    "raw = raw.set_eeg_reference(ref_channels = macro_ref, ch_type = 'seeg')\n",
    "\n",
    "# Re-reference scalp electrodes to scalp-CAR\n",
    "scalp_ref = ch_dictionary[ch_dictionary['type'] == 'scalp']['name'].to_list()\n",
    "raw = raw.set_eeg_reference(ref_channels = scalp_ref, ch_type = 'eeg')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subset electrodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LeGUI channel selection (but keep scalp, eog, and ecg)\n",
    "print('Original channel count:', len(raw.info.ch_names))\n",
    "legui_df = pd.read_csv(legui_path)\n",
    "legui_df = legui_df.loc[(legui_df.status == 'accept') & (legui_df.type == 'macro')]\n",
    "legui_channels = legui_df.elec_label.to_numpy()\n",
    "other_channels = ch_dictionary.loc[ch_dictionary['type'].isin(['scalp', 'ecg', 'eog']), 'name']\n",
    "keep_channels_2 = legui_channels.tolist() + other_channels.tolist()\n",
    "raw = raw.pick_channels(keep_channels_2)\n",
    "print('Channels after LeGUI selection:', len(raw.ch_names))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.save(save_path, overwrite = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sandbox",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "bceaa3bdda3825794b37c15d2000316b6f4a45a3d4f5e14660beed4f1d5f7638"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
