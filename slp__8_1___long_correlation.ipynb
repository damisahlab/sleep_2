{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "import pandas as pd\n",
    "from scipy.stats import spearmanr\n",
    "#from dcor import distance_correlation\n",
    "from pingouin import distance_corr\n",
    "from statsmodels.stats.multitest import fdrcorrection\n",
    "\n",
    "import utils__config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'g:\\\\My Drive\\\\Residency\\\\Research\\\\Lab - Damisah\\\\Project - Sleep'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(utils__config.working_directory)\n",
    "os.getcwd()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypno_epoch_path = 'Cache/Subject01/S01_hypno_epochs_30s.csv' \n",
    "spike_epoch_path = 'Cache/Subject01/S01_spike_epochs_30s.csv'\n",
    "hyp_out_path = 'Cache/Subject01/S01_hyp_correlation.csv'\n",
    "\n",
    "# hypno_epoch_path = 'Cache/Subject02/Apr26/S02_hypno_epochs_30s.csv'\n",
    "# spike_epoch_path = 'Cache/Subject02/Apr26/S02_spike_epochs_30s.csv'\n",
    "# hyp_out_path = 'Cache/Subject02/Apr26/S02_hyp_correlation.csv'\n",
    "\n",
    "# hypno_epoch_path = 'Cache/Subject02/Apr27/S02_hypno_epochs_30s.csv'\n",
    "# spike_epoch_path = 'Cache/Subject02/Apr27/S02_spike_epochs_30s.csv'\n",
    "# hyp_out_path = 'Cache/Subject02/Apr27/S02_hyp_correlation.csv'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "hypno = pd.read_csv(hypno_epoch_path)\n",
    "spikes = pd.read_csv(spike_epoch_path)\n",
    "\n",
    "# Merge with hypnogram to get sleep stage\n",
    "spikes = spikes.merge(hypno, on = 'epoch')\n",
    "spikes['sw_stage'] = np.where(spikes['stage'].isin([2, 3]), 1, 0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation with sleep stage by epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = pd.DataFrame()\n",
    "\n",
    "for unit in spikes['unit_id'].unique():\n",
    "\n",
    "    # Get laterality and region for the unit\n",
    "    # (we need to use the .iloc[0] function because the index\n",
    "    # is not reset to 0 in these slices and we don't know what\n",
    "    # those index numbers will start with...)\n",
    "    unit_laterality = spikes[spikes['unit_id'] == unit]['unit_laterality'].iloc[0]\n",
    "    unit_region = spikes[spikes['unit_id'] == unit]['unit_region'].iloc[0]\n",
    "\n",
    "    # Select only the relevant Spikes data\n",
    "    spikes_temp = spikes[spikes['unit_id'] == unit][['epoch', 'fr', 'sw_stage']]\n",
    "\n",
    "    # Spearman's Rho (non-linear correlation; old and reliable)\n",
    "    r, r_p = spearmanr(spikes_temp['sw_stage'], spikes_temp['fr'])\n",
    "    \n",
    "    # Distance Correlation (non-linear correlation; new and shiny)\n",
    "    # (The implementation from dcor does not return a p-value unless\n",
    "    #  you use one of their more complicated functions)\n",
    "    d, d_p = distance_corr(x = spikes_temp['sw_stage'], \n",
    "                           y = spikes_temp['fr'],\n",
    "                           alternative = 'two-sided',\n",
    "                           n_boot = 10, # or 1000\n",
    "                           seed = 42)\n",
    "\n",
    "    # Append to dataframe\n",
    "    unit_corr = pd.DataFrame({'unit_id' : [unit],\n",
    "                              'unit_region' : [unit_region],\n",
    "                              'unit_laterality' : [unit_laterality],\n",
    "                              'rho' : [r],\n",
    "                              'rho_p_value' : [r_p],\n",
    "                              'dcor' : [d],\n",
    "                              'dcor_p_value' : [d_p]})\n",
    "\n",
    "    corr = pd.concat([corr, unit_corr])\n",
    "\n",
    "corr['fdr_rho_p_value'] = fdrcorrection(corr['rho_p_value'], alpha = 0.05, method = 'indep')[1]\n",
    "corr['fdr_dcor_p_value'] = fdrcorrection(corr['dcor_p_value'], alpha = 0.05, method = 'indep')[1]\n",
    "\n",
    "corr.to_csv(hyp_out_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sandbox",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bceaa3bdda3825794b37c15d2000316b6f4a45a3d4f5e14660beed4f1d5f7638"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
