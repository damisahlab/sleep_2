{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\layto\\.conda\\envs\\sandbox\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import io\n",
    "import hdf5storage\n",
    "from tqdm import tqdm\n",
    "\n",
    "import utils__config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'G:\\\\My Drive\\\\Residency\\\\Research\\\\Lab - Damisah\\\\Project - Sleep\\\\Revisions'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(utils__config.working_directory)\n",
    "os.getcwd()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = 'Cache/Subject01/Feb02/S01_Feb02_cnato__5___yemi_to_mat'\n",
    "dict_dir = 'Data/Subject01/S01_dictionary.xlsx'\n",
    "metric_dir = 'Cache/Subject01/Feb02/S01_spike_metrics.csv'\n",
    "out_dir = 'Cache/Subject01/Feb02/S01_waveforms_sampled.csv'\n",
    "\n",
    "# root_dir = 'Cache/Subject05/Jul11/S05_Jul11_cnato__4___yemi_to_mat'\n",
    "# dict_dir = 'Data/Subject05/S05_dictionary.xlsx'\n",
    "# metric_dir = 'Cache/Subject05/Jul11/S05_spike_metrics.csv'\n",
    "# out_dir = 'Cache/Subject05/Jul11/S05_waveforms_sampled.csv'\n",
    "\n",
    "# root_dir = 'Cache/Subject05/Jul12/S05_Jul12_cnato__4___yemi_to_mat'\n",
    "# dict_dir = 'Data/Subject05/S05_dictionary.xlsx'\n",
    "# metric_dir = 'Cache/Subject05/Jul12/S05_spike_metrics.csv'\n",
    "# out_dir = 'Cache/Subject05/Jul12/S05_waveforms_sampled.csv'\n",
    "\n",
    "# root_dir = 'Cache/Subject05/Jul13/S05_Jul13_cnato__4___yemi_to_mat'\n",
    "# dict_dir = 'Data/Subject05/S05_dictionary.xlsx'\n",
    "# metric_dir = 'Cache/Subject05/Jul13/S05_spike_metrics.csv'\n",
    "# out_dir = 'Cache/Subject05/Jul13/S05_waveforms_sampled.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = 1000\n",
    "MAT_version = '7.3' # MAT file version (SciPy reads < 7.3, hdf5storage reads >= 7.3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Munging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "micro_dict = pd.read_excel(dict_dir)\n",
    "micro_dict = micro_dict[['number', 'laterality', 'region']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame()\n",
    "\n",
    "for channel in tqdm(os.listdir(root_dir)):\n",
    "\n",
    "    if MAT_version == '7.3':\n",
    "        raw_data = hdf5storage.loadmat(os.path.join(root_dir, channel))\n",
    "    else:\n",
    "        raw_data = io.loadmat(os.path.join(root_dir, channel))\n",
    "\n",
    "    chan_data = pd.DataFrame()\n",
    "\n",
    "    # Extract unit type and spike times\n",
    "    for unit in np.arange(0, len(raw_data['sp_types'])):\n",
    "\n",
    "        # Extract and format spike waveforms\n",
    "        unit_data = pd.DataFrame(raw_data['sp_waveforms'][unit][0])\n",
    "        unit_data = unit_data.reset_index()\n",
    "        unit_data['index'] = unit_data['index'] + 1\n",
    "        unit_data = pd.melt(unit_data, id_vars = 'index')\n",
    "        unit_data.columns = ['time_point', 'spike_id', 'amplitude']\n",
    "\n",
    "        # Skip iteration if empty\n",
    "        if len(unit_data) == 0:\n",
    "            continue\n",
    "\n",
    "        # Extract and merge spike times\n",
    "        unit_times = pd.DataFrame(raw_data['sp_times'][unit][0])\n",
    "        unit_times.columns = ['milliseconds']\n",
    "        unit_times['spike_id'] = unit_times.index\n",
    "        unit_data = pd.merge(unit_data, unit_times, on='spike_id', how='inner')\n",
    "\n",
    "        # Randomly sample unique spike ids if their count is greater than 'samples'\n",
    "        unique_spike_ids = unit_data['spike_id'].unique()\n",
    "        \n",
    "        if len(unique_spike_ids) > samples:\n",
    "            sampled_spike_ids = np.random.choice(unique_spike_ids, size=samples, replace=False)\n",
    "            unit_data = unit_data[unit_data['spike_id'].isin(sampled_spike_ids)]\n",
    "\n",
    "        # Set unit meta-data\n",
    "        unit_data['unit_type'] = raw_data['sp_types'][unit][0]\n",
    "        unit_data['unit_num'] = unit + 1\n",
    "\n",
    "        # Merge up a level\n",
    "        chan_data = pd.concat([chan_data, unit_data])\n",
    "    \n",
    "    # Set channel meta-data\n",
    "    chan_data['subject'] = channel.split('_')[0]\n",
    "\n",
    "    chan_data['channel'] = channel.split('_')[1]\n",
    "    chan_data['channel'] = chan_data['channel'].str.split('l', expand = True)[1]\n",
    "    chan_data['channel'] = chan_data['channel'].astype('int64') # to merge with micro_dict\n",
    "\n",
    "    chan_data['sign'] = channel.split('_')[2]\n",
    "    chan_data['sign'] = chan_data['sign'].str.split('.', expand = True)[0]\n",
    "\n",
    "    # Merge up a level\n",
    "    data = pd.concat([data, chan_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge with dictionary meta-data\n",
    "data = data.merge(micro_dict, left_on = 'channel', right_on = 'number')\n",
    "\n",
    "# Account for the offset in unit number between Combinato and MATLAB\n",
    "# so that you can compare units between Combinato GUI and your analysis (optional)\n",
    "data['unit_num'] = data['unit_num'] - 1\n",
    "\n",
    "# Create a unique unit ID\n",
    "data['unit_id'] = data['subject'] + '_Ch' + data['channel'].astype('str') + '_' + data['sign'] + '_Unit' + data['unit_num'].astype('str')\n",
    "\n",
    "# Rename laterality/region columns to specify that they apply to the unit\n",
    "data.rename(columns = {'laterality' : 'unit_laterality', 'region' : 'unit_region'}, inplace = True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quality Control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove artifactual units\n",
    "# (artifact = -1 | unassigned = 0 | MUA = 1 | SUA = 2)\n",
    "#data = data[data['unit_type'] == 2] # SUA only\n",
    "data = data[(data['unit_type'] != -1) & (data['unit_type'] != 0)] # SUA + MUA\n",
    "\n",
    "# Keep only units from CLA, AMY, ACC, or aINS\n",
    "data = data[(data['unit_region'] == 'CLA') | (data['unit_region'] == 'AMY') | \n",
    "            (data['unit_region'] == 'ACC') | (data['unit_region'] == 'aINS')]\n",
    "\n",
    "# Keep only units selected by the quality control script\n",
    "spike_metrics = pd.read_csv(metric_dir)\n",
    "data = data[data['unit_id'].isin(spike_metrics['unit_id'])]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to CSV\n",
    "data = data.drop(['unit_type', 'unit_num', 'subject', 'channel', 'number', 'sign'], axis=1)\n",
    "data.to_csv(out_dir, index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sandbox",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
