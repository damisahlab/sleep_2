{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "\n",
    "from tqdm import tqdm\n",
    "from pandas.arrays import IntervalArray\n",
    "\n",
    "import mne\n",
    "from mne.time_frequency import tfr_array_morlet\n",
    "from scipy.stats import zscore\n",
    "\n",
    "from utils__helpers_macro import hilbert_powerphase, hilbert_envelope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'G:\\\\My Drive\\\\Residency\\\\Research\\\\Lab - Damisah\\\\Project - Sleep\\\\Revisions'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import utils__config\n",
    "os.chdir(utils__config.working_directory)\n",
    "os.getcwd()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters\n",
    "Please note that .FIF files that are split (due to the 2GB size limit) will have their original name saved internally as well, so manually renaming files at a later date will result in being unable to load the file, as the first file in the split will have its original internal name that serves as a template for finding split files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fif_path = 'Data/S01_Feb02_256hz.fif'\n",
    "# spike_path = 'Data/S01_Feb02_spike_times.csv'\n",
    "# hypno_path = 'Data/S01_Feb02_hypnogram.csv' \n",
    "# legui_path = 'Data/S01_electrodes.csv'\n",
    "# bad_channel_path = 'Data/S01_Feb02_bad_channels.csv'\n",
    "# output_path = 'Cache/S01_Feb02_sf_coupling.csv'\n",
    "\n",
    "fif_path = 'Data/S05_Jul11_256hz.fif'\n",
    "spike_path = 'Data/S05_Jul11_spike_times.csv'\n",
    "hypno_path = 'Data/S05_Jul11_hypnogram.csv' \n",
    "legui_path = 'Data/S05_electrodes.csv'\n",
    "bad_channel_path = 'Data/S05_Jul11_bad_channels.csv'\n",
    "output_path = 'Cache/S05_Jul11_sf_coupling.csv'\n",
    "\n",
    "# fif_path = 'Data/S05_Jul12_256hz.fif'\n",
    "# spike_path = 'Data/S05_Jul12_spike_times.csv'\n",
    "# hypno_path = 'Data/S05_Jul12_hypnogram.csv' \n",
    "# legui_path = 'Data/S05_electrodes.csv'\n",
    "# bad_channel_path = 'Data/S05_Jul12_bad_channels.csv'\n",
    "# output_path = 'Cache/S05_Jul12_sf_coupling.csv'\n",
    "\n",
    "# fif_path = 'Data/S05_Jul13_256hz.fif'\n",
    "# spike_path = 'Data/S05_Jul13_spike_times.csv'\n",
    "# hypno_path = 'Data/S05_Jul13_hypnogram.csv' \n",
    "# legui_path = 'Data/S05_electrodes.csv'\n",
    "# bad_channel_path = 'Data/S05_Jul13_bad_channels.csv'\n",
    "# output_path = 'Cache/S05_Jul13_sf_coupling.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_freq = 256"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file Data/S05_Jul11_256hz.fif...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\layto\\AppData\\Local\\Temp\\ipykernel_17320\\1663171324.py:1: RuntimeWarning: This filename (Data/S05_Jul11_256hz.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw = mne.io.read_raw_fif(fif_path, preload = True, verbose = None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Range : 0 ... 7249663 =      0.000 ... 28318.996 secs\n",
      "Ready.\n",
      "Opening raw data file G:\\My Drive\\Residency\\Research\\Lab - Damisah\\Project - Sleep\\Revisions\\Data\\S05_Jul11_256hz-1.fif...\n",
      "    Range : 7249664 ... 8921599 =  28319.000 ... 34849.996 secs\n",
      "Ready.\n",
      "Reading 0 ... 8921599  =      0.000 ... 34849.996 secs...\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    }
   ],
   "source": [
    "raw = mne.io.read_raw_fif(fif_path, preload = True, verbose = None)\n",
    "\n",
    "# Select only macroelectrodes\n",
    "raw.pick_types(seeg = True, ecog = True)\n",
    "\n",
    "# Remove rejected channels\n",
    "bad_channels = pd.read_csv(bad_channel_path)\n",
    "bad_channels = bad_channels[bad_channels['channel'].isin(raw.ch_names)]\n",
    "raw.drop_channels(ch_names = bad_channels['channel'].astype('string'))\n",
    "\n",
    "# Load LeGUI data\n",
    "legui = pd.read_csv(legui_path)\n",
    "legui = legui[['elec_label', 'hemisphere', 'roi_1']]\n",
    "legui.columns = ['channel', 'laterality', 'region']\n",
    "\n",
    "# Load Spike data\n",
    "spikes = pd.read_csv(spike_path)\n",
    "spikes = spikes[['unit_id', 'seconds', 'unit_laterality', 'unit_region']]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract slow-wave-band phase and delta power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.3 - 1.5 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.30\n",
      "- Lower transition bandwidth: 0.30 Hz (-6 dB cutoff frequency: 0.15 Hz)\n",
      "- Upper passband edge: 1.50 Hz\n",
      "- Upper transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 2.50 Hz)\n",
      "- Filter length: 2817 samples (11.004 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  12 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=6)]: Done  53 out of  53 | elapsed:   11.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting \"channel\" to \"category\"...\n",
      "Converting \"ch_type\" to \"category\"...\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.3 - 4 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.30\n",
      "- Lower transition bandwidth: 0.30 Hz (-6 dB cutoff frequency: 0.15 Hz)\n",
      "- Upper passband edge: 4.00 Hz\n",
      "- Upper transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 5.00 Hz)\n",
      "- Filter length: 2817 samples (11.004 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  12 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=6)]: Done  53 out of  53 | elapsed:    6.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting \"channel\" to \"category\"...\n",
      "Converting \"ch_type\" to \"category\"...\n"
     ]
    }
   ],
   "source": [
    "# Extract Slow-Wave-band Phase\n",
    "swb = raw.copy()\n",
    "swb = hilbert_powerphase(data = swb, lower = 0.3, upper = 1.5, njobs = 6)\n",
    "swb = swb[['time', 'channel', 'power', 'phase']]\n",
    "swb.columns = ['time', 'channel', 'swb_power', 'swb_phase']\n",
    "\n",
    "# Extract Delta Power\n",
    "delta = raw.copy()\n",
    "delta = hilbert_powerphase(data = delta, lower = 0.3, upper = 4, njobs = 6)\n",
    "delta = delta[['time', 'channel', 'power', 'phase']]\n",
    "delta.columns = ['time', 'channel', 'd_power', 'd_phase']\n",
    "\n",
    "# Merge slow-wave-band phase and delta power\n",
    "lfp = swb.merge(delta, on = ['time', 'channel'])\n",
    "lfp = lfp[['time', 'channel', 'swb_phase', 'd_power']]\n",
    "lfp.columns = ['time', 'channel', 'phase', 'power']\n",
    "\n",
    "# Log-normalize and z-score the delta power\n",
    "lfp['log_power'] = 10 * np.log10(lfp['power'])\n",
    "lfp['zlog_power'] = lfp.groupby(['channel'])['log_power'].transform(zscore)\n",
    "\n",
    "# Merge with LeGUI data to get LFP laterality and region\n",
    "lfp = lfp.merge(legui, on = 'channel', how = 'inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add sleep stage to LFP data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load hypnogram\n",
    "hypno = pd.read_csv(hypno_path, header = None)\n",
    "hypno = hypno.reset_index()\n",
    "hypno.columns = ['sample', 'stage']\n",
    "hypno['time'] = hypno['sample'] / sampling_freq\n",
    "\n",
    "# Hypnogram dictionary: \n",
    "# (-2) = Unassigned\n",
    "# (-1) = Artifact\n",
    "# (0) = Awake\n",
    "# (1) = N1\n",
    "# (2) = N2\n",
    "# (3) = N3\n",
    "# (4) = REM\n",
    "\n",
    "# Extract and group sleep stages\n",
    "hypno['stage'] = np.where(hypno['stage'].isin([2, 3]), 'NREM', 'WREM')\n",
    "\n",
    "# Merge with hypnogram\n",
    "lfp = pd.merge_asof(lfp.sort_values('time'), hypno.sort_values('time'),\n",
    "                    left_on = 'time', right_on = 'time', direction = 'nearest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define DREM sleep (high delta power NREM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate percentile of power (only NREM rows)\n",
    "lfp['nrem_tile'] = np.nan\n",
    "lfp.loc[lfp['stage'] == 'NREM', 'nrem_tile'] = lfp.loc[lfp['stage'] == 'NREM', 'power'].rank(pct=True)\n",
    "\n",
    "# Generate DREM column based on 75th percentile of NREM power\n",
    "lfp['DREM'] = np.where((lfp['nrem_tile'] >= 0.75) & (lfp['stage'] == 'NREM'), 1, 0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intersect spikes with nearest values of LFP/hypno data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [22:02<00:00, 24.96s/it]\n"
     ]
    }
   ],
   "source": [
    "data = pd.DataFrame()\n",
    "\n",
    "for chan in tqdm(lfp.channel.unique()):\n",
    "\n",
    "    # Subset the phase-envelope dataset\n",
    "    lfp_channel = lfp[lfp.channel == chan].copy(deep = True)\n",
    "\n",
    "    # For every spike, find the nearest \n",
    "    # sample in the phase-envelope dataset...\n",
    "    data_temp = pd.merge_asof(spikes.sort_values('seconds'), lfp_channel.sort_values('time'), \n",
    "                              left_on = 'seconds', right_on = 'time', direction = 'nearest')\n",
    "\n",
    "    data_temp.drop(columns = ['time', 'sample'], inplace = True)\n",
    "\n",
    "    # Concatenate into final dataset\n",
    "    data = pd.concat((data, data_temp))\n",
    "\n",
    "data = data[['stage', 'DREM', 'channel', 'laterality', 'region', \n",
    "             'unit_id', 'unit_laterality', 'unit_region', \n",
    "             'phase', 'power', 'seconds']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Further reduce columns to save space\n",
    "data = data[['stage', 'DREM', 'channel', 'unit_id', 'phase', 'power']]\n",
    "\n",
    "# Export\n",
    "data.to_csv(output_path, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stage</th>\n",
       "      <th>DREM</th>\n",
       "      <th>channel</th>\n",
       "      <th>unit_id</th>\n",
       "      <th>phase</th>\n",
       "      <th>power</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WREM</td>\n",
       "      <td>0</td>\n",
       "      <td>LOF1</td>\n",
       "      <td>S05_Ch240_neg_Unit1</td>\n",
       "      <td>1.818339</td>\n",
       "      <td>0.003713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WREM</td>\n",
       "      <td>0</td>\n",
       "      <td>LOF1</td>\n",
       "      <td>S05_Ch234_neg_Unit2</td>\n",
       "      <td>1.818339</td>\n",
       "      <td>0.003713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WREM</td>\n",
       "      <td>0</td>\n",
       "      <td>LOF1</td>\n",
       "      <td>S05_Ch240_neg_Unit1</td>\n",
       "      <td>1.923831</td>\n",
       "      <td>0.004137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WREM</td>\n",
       "      <td>0</td>\n",
       "      <td>LOF1</td>\n",
       "      <td>S05_Ch240_neg_Unit1</td>\n",
       "      <td>1.990766</td>\n",
       "      <td>0.004375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WREM</td>\n",
       "      <td>0</td>\n",
       "      <td>LOF1</td>\n",
       "      <td>S05_Ch234_neg_Unit2</td>\n",
       "      <td>2.118140</td>\n",
       "      <td>0.004765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3862203</th>\n",
       "      <td>WREM</td>\n",
       "      <td>0</td>\n",
       "      <td>LAC7</td>\n",
       "      <td>S05_Ch194_neg_Unit4</td>\n",
       "      <td>-0.154210</td>\n",
       "      <td>0.000942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3862204</th>\n",
       "      <td>WREM</td>\n",
       "      <td>0</td>\n",
       "      <td>LAC7</td>\n",
       "      <td>S05_Ch210_neg_Unit2</td>\n",
       "      <td>-0.154210</td>\n",
       "      <td>0.000942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3862205</th>\n",
       "      <td>WREM</td>\n",
       "      <td>0</td>\n",
       "      <td>LAC7</td>\n",
       "      <td>S05_Ch194_neg_Unit4</td>\n",
       "      <td>0.287288</td>\n",
       "      <td>0.001512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3862206</th>\n",
       "      <td>WREM</td>\n",
       "      <td>0</td>\n",
       "      <td>LAC7</td>\n",
       "      <td>S05_Ch194_neg_Unit2</td>\n",
       "      <td>0.357987</td>\n",
       "      <td>0.001573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3862207</th>\n",
       "      <td>WREM</td>\n",
       "      <td>0</td>\n",
       "      <td>LAC7</td>\n",
       "      <td>S05_Ch194_neg_Unit2</td>\n",
       "      <td>0.727726</td>\n",
       "      <td>0.001674</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>204697024 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        stage  DREM channel              unit_id     phase     power\n",
       "0        WREM     0    LOF1  S05_Ch240_neg_Unit1  1.818339  0.003713\n",
       "1        WREM     0    LOF1  S05_Ch234_neg_Unit2  1.818339  0.003713\n",
       "2        WREM     0    LOF1  S05_Ch240_neg_Unit1  1.923831  0.004137\n",
       "3        WREM     0    LOF1  S05_Ch240_neg_Unit1  1.990766  0.004375\n",
       "4        WREM     0    LOF1  S05_Ch234_neg_Unit2  2.118140  0.004765\n",
       "...       ...   ...     ...                  ...       ...       ...\n",
       "3862203  WREM     0    LAC7  S05_Ch194_neg_Unit4 -0.154210  0.000942\n",
       "3862204  WREM     0    LAC7  S05_Ch210_neg_Unit2 -0.154210  0.000942\n",
       "3862205  WREM     0    LAC7  S05_Ch194_neg_Unit4  0.287288  0.001512\n",
       "3862206  WREM     0    LAC7  S05_Ch194_neg_Unit2  0.357987  0.001573\n",
       "3862207  WREM     0    LAC7  S05_Ch194_neg_Unit2  0.727726  0.001674\n",
       "\n",
       "[204697024 rows x 6 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sandbox",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bceaa3bdda3825794b37c15d2000316b6f4a45a3d4f5e14660beed4f1d5f7638"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
