{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lal85\\AppData\\Local\\miniconda3\\envs\\wavemap\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.preprocessing\n",
    "\n",
    "import umap\n",
    "from scipy.integrate import simps\n",
    "from scipy.spatial.distance import euclidean\n",
    "\n",
    "from scipy.spatial.distance import mahalanobis\n",
    "from scipy.linalg import inv\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from scipy.stats import chi2\n",
    "\n",
    "import utils__config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Z:\\\\Layton\\\\Sleep_051324'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(utils__config.working_directory)\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "recordings = [\n",
    "    {\n",
    "        'recording_id': 'Feb02',\n",
    "        'recording_length': 2,\n",
    "        'mean_waveforms': 'Data/S01_Feb02_mean_waveforms.csv',\n",
    "        'sampled_waveforms': 'Data/S01_Feb02_waveforms_sampled.csv'\n",
    "    },\n",
    "    {\n",
    "        'recording_id': 'Jul11',\n",
    "        'recording_length': 9.68,\n",
    "        'mean_waveforms': 'Data/S05_Jul11_mean_waveforms.csv',\n",
    "        'sampled_waveforms': 'Data/S05_Jul11_waveforms_sampled.csv'\n",
    "    },\n",
    "    {\n",
    "        'recording_id': 'Jul12',\n",
    "        'recording_length': 10.55,\n",
    "        'mean_waveforms': 'Data/S05_Jul12_mean_waveforms.csv',\n",
    "        'sampled_waveforms': 'Data/S05_Jul12_waveforms_sampled.csv'\n",
    "    },\n",
    "    {\n",
    "        'recording_id': 'Jul13',\n",
    "        'recording_length': 10.40,\n",
    "        'mean_waveforms': 'Data/S05_Jul13_mean_waveforms.csv',\n",
    "        'sampled_waveforms': 'Data/S05_Jul13_waveforms_sampled.csv'\n",
    "    }\n",
    "]\n",
    "\n",
    "output_path = 'Cache/waveform_stability.csv'\n",
    "\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame()\n",
    "\n",
    "for recording in recordings:\n",
    "    \n",
    "    # Process mean_waveforms\n",
    "    mean_waveforms = pd.read_csv(recording['mean_waveforms'])\n",
    "    mean_waveforms['type'] = 'mean'\n",
    "    mean_waveforms['percent'] = np.NaN\n",
    "    mean_waveforms['spike_id'] = mean_waveforms.apply(lambda row: str(row['spike_id']) + \"_\" + str('mean'), axis=1)\n",
    "    \n",
    "    # Process sampled_waveforms\n",
    "    sampled_waveforms = pd.read_csv(recording['sampled_waveforms'])\n",
    "    sampled_waveforms['type'] = 'sample'\n",
    "    sampled_waveforms['percent'] = ((sampled_waveforms['milliseconds'] / 1000) / (recording['recording_length'] * 3600)) * 100\n",
    "    sampled_waveforms['spike_id'] = sampled_waveforms.apply(lambda row: str(row['spike_id']) + \"_\" + str('sample'), axis=1)\n",
    "\n",
    "    # Row bind mean_waveforms and sampled_waveforms\n",
    "    combined = pd.concat([mean_waveforms, sampled_waveforms], ignore_index=True)\n",
    "    combined['unit_id'] = combined['unit_id'].astype(str) + '_' + recording['recording_id']\n",
    "    combined['spike_id'] = combined.apply(lambda row: str(row['spike_id']) + \"_\" + str(row['unit_id']), axis=1)\n",
    "    \n",
    "    # Append to data\n",
    "    data = pd.concat([data, combined], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unit_laterality</th>\n",
       "      <th>unit_region</th>\n",
       "      <th>unit_id</th>\n",
       "      <th>type</th>\n",
       "      <th>spike_id</th>\n",
       "      <th>percent</th>\n",
       "      <th>time_point</th>\n",
       "      <th>amplitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2368</th>\n",
       "      <td>right</td>\n",
       "      <td>CLA</td>\n",
       "      <td>S01_Ch195_neg_Unit3_Feb02</td>\n",
       "      <td>sample</td>\n",
       "      <td>38</td>\n",
       "      <td>0.041281</td>\n",
       "      <td>1</td>\n",
       "      <td>6.967503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2369</th>\n",
       "      <td>right</td>\n",
       "      <td>CLA</td>\n",
       "      <td>S01_Ch195_neg_Unit3_Feb02</td>\n",
       "      <td>sample</td>\n",
       "      <td>38</td>\n",
       "      <td>0.041281</td>\n",
       "      <td>2</td>\n",
       "      <td>4.712843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2370</th>\n",
       "      <td>right</td>\n",
       "      <td>CLA</td>\n",
       "      <td>S01_Ch195_neg_Unit3_Feb02</td>\n",
       "      <td>sample</td>\n",
       "      <td>38</td>\n",
       "      <td>0.041281</td>\n",
       "      <td>3</td>\n",
       "      <td>0.827369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2371</th>\n",
       "      <td>right</td>\n",
       "      <td>CLA</td>\n",
       "      <td>S01_Ch195_neg_Unit3_Feb02</td>\n",
       "      <td>sample</td>\n",
       "      <td>38</td>\n",
       "      <td>0.041281</td>\n",
       "      <td>4</td>\n",
       "      <td>-1.831863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2372</th>\n",
       "      <td>right</td>\n",
       "      <td>CLA</td>\n",
       "      <td>S01_Ch195_neg_Unit3_Feb02</td>\n",
       "      <td>sample</td>\n",
       "      <td>38</td>\n",
       "      <td>0.041281</td>\n",
       "      <td>5</td>\n",
       "      <td>-2.136348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7815803</th>\n",
       "      <td>right</td>\n",
       "      <td>AMY</td>\n",
       "      <td>S05_Ch240_neg_Unit3_Jul13</td>\n",
       "      <td>sample</td>\n",
       "      <td>122122</td>\n",
       "      <td>99.976814</td>\n",
       "      <td>60</td>\n",
       "      <td>16.517321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7815804</th>\n",
       "      <td>right</td>\n",
       "      <td>AMY</td>\n",
       "      <td>S05_Ch240_neg_Unit3_Jul13</td>\n",
       "      <td>sample</td>\n",
       "      <td>122122</td>\n",
       "      <td>99.976814</td>\n",
       "      <td>61</td>\n",
       "      <td>8.810473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7815805</th>\n",
       "      <td>right</td>\n",
       "      <td>AMY</td>\n",
       "      <td>S05_Ch240_neg_Unit3_Jul13</td>\n",
       "      <td>sample</td>\n",
       "      <td>122122</td>\n",
       "      <td>99.976814</td>\n",
       "      <td>62</td>\n",
       "      <td>4.711396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7815806</th>\n",
       "      <td>right</td>\n",
       "      <td>AMY</td>\n",
       "      <td>S05_Ch240_neg_Unit3_Jul13</td>\n",
       "      <td>sample</td>\n",
       "      <td>122122</td>\n",
       "      <td>99.976814</td>\n",
       "      <td>63</td>\n",
       "      <td>4.422690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7815807</th>\n",
       "      <td>right</td>\n",
       "      <td>AMY</td>\n",
       "      <td>S05_Ch240_neg_Unit3_Jul13</td>\n",
       "      <td>sample</td>\n",
       "      <td>122122</td>\n",
       "      <td>99.976814</td>\n",
       "      <td>64</td>\n",
       "      <td>6.247863</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7808000 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        unit_laterality unit_region                    unit_id    type  \\\n",
       "2368              right         CLA  S01_Ch195_neg_Unit3_Feb02  sample   \n",
       "2369              right         CLA  S01_Ch195_neg_Unit3_Feb02  sample   \n",
       "2370              right         CLA  S01_Ch195_neg_Unit3_Feb02  sample   \n",
       "2371              right         CLA  S01_Ch195_neg_Unit3_Feb02  sample   \n",
       "2372              right         CLA  S01_Ch195_neg_Unit3_Feb02  sample   \n",
       "...                 ...         ...                        ...     ...   \n",
       "7815803           right         AMY  S05_Ch240_neg_Unit3_Jul13  sample   \n",
       "7815804           right         AMY  S05_Ch240_neg_Unit3_Jul13  sample   \n",
       "7815805           right         AMY  S05_Ch240_neg_Unit3_Jul13  sample   \n",
       "7815806           right         AMY  S05_Ch240_neg_Unit3_Jul13  sample   \n",
       "7815807           right         AMY  S05_Ch240_neg_Unit3_Jul13  sample   \n",
       "\n",
       "         spike_id    percent  time_point  amplitude  \n",
       "2368           38   0.041281           1   6.967503  \n",
       "2369           38   0.041281           2   4.712843  \n",
       "2370           38   0.041281           3   0.827369  \n",
       "2371           38   0.041281           4  -1.831863  \n",
       "2372           38   0.041281           5  -2.136348  \n",
       "...           ...        ...         ...        ...  \n",
       "7815803    122122  99.976814          60  16.517321  \n",
       "7815804    122122  99.976814          61   8.810473  \n",
       "7815805    122122  99.976814          62   4.711396  \n",
       "7815806    122122  99.976814          63   4.422690  \n",
       "7815807    122122  99.976814          64   6.247863  \n",
       "\n",
       "[7808000 rows x 8 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Format data and set final spike_id\n",
    "data = data[['unit_laterality', 'unit_region', 'unit_id', 'type', 'spike_id', 'percent', 'time_point', 'amplitude']]\n",
    "data['spike_id'] = pd.factorize(data['spike_id'])[0] + 1\n",
    "data\n",
    "\n",
    "# Filter out the mean waveforms for use as reference in calculating Euclidean distances\n",
    "mean_waveforms = data[data['type'] == 'mean']\n",
    "\n",
    "# Calculate metrics for sample waveforms\n",
    "sample_waveforms = data[data['type'] == 'sample']\n",
    "sample_waveforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Stability Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_unit_metrics(df, mean_waveforms):\n",
    "    # Initialize results list\n",
    "    results = []\n",
    "\n",
    "    for unit_id, group in df.groupby('unit_id'):\n",
    "        polarity = 'neg' if 'neg' in unit_id else 'pos'\n",
    "        metrics = {\n",
    "            'fwhm': [],\n",
    "            'auc': [],\n",
    "            'max_amplitude': [],\n",
    "            'euclidean_distance': []\n",
    "        }\n",
    "        \n",
    "        mean_waveform = mean_waveforms[(mean_waveforms['unit_id'] == unit_id)].sort_values('time_point')['amplitude'].values\n",
    "        \n",
    "        for _, spike_group in group.groupby('spike_id'):\n",
    "            waveform = spike_group.sort_values('time_point')['amplitude'].values\n",
    "            \n",
    "            # Handle polarity\n",
    "            if polarity == 'neg':\n",
    "                waveform = -waveform  # Flip waveform for negative-spiking units\n",
    "            \n",
    "            # Calculate AUC\n",
    "            auc = simps(waveform, dx=1)\n",
    "            metrics['auc'].append(auc)\n",
    "            \n",
    "            # Calculate Maximum Amplitude\n",
    "            max_amplitude = np.max(waveform)\n",
    "            metrics['max_amplitude'].append(max_amplitude)\n",
    "            \n",
    "            # Calculate FWHM\n",
    "            half_max = max_amplitude / 2\n",
    "            indices_above_half_max = np.where(waveform >= half_max)[0]\n",
    "            fwhm = indices_above_half_max[-1] - indices_above_half_max[0] if len(indices_above_half_max) > 0 else np.nan\n",
    "            metrics['fwhm'].append(fwhm)\n",
    "            \n",
    "            # Calculate Euclidean distance from the mean waveform\n",
    "            if len(mean_waveform) == len(waveform):\n",
    "                euclidean_dist = euclidean(mean_waveform, waveform)\n",
    "                metrics['euclidean_distance'].append(euclidean_dist)\n",
    "\n",
    "        # Calculate Coefficient of Variation for each metric\n",
    "        cv_results = {\n",
    "            'unit_id': unit_id,\n",
    "            'fwhm_cv': np.std(metrics['fwhm']) / np.mean(metrics['fwhm']) if np.mean(metrics['fwhm']) else np.nan,\n",
    "            'auc_cv': np.std(metrics['auc']) / np.mean(metrics['auc']) if np.mean(metrics['auc']) else np.nan,\n",
    "            'max_amplitude_cv': np.std(metrics['max_amplitude']) / np.mean(metrics['max_amplitude']) if np.mean(metrics['max_amplitude']) else np.nan,\n",
    "            'euclidean_distance_cv': np.std(metrics['euclidean_distance']) / np.mean(metrics['euclidean_distance']) if np.mean(metrics['euclidean_distance']) else np.nan\n",
    "        }\n",
    "        results.append(cv_results)\n",
    "\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_umap(df):\n",
    "    # Ensure the DataFrame is sorted by unit_id, spike_id, and time_point for consistent row ordering\n",
    "    sorted_df = df.sort_values(['unit_id', 'spike_id', 'time_point'])\n",
    "\n",
    "    # Pivot the data to create a 2D array where each row represents a spike and columns are time points\n",
    "    waveforms = sorted_df.pivot(index='spike_id', columns='time_point', values='amplitude').values\n",
    "\n",
    "    # Initialize UMAP reducer\n",
    "    reducer = umap.UMAP(n_neighbors=15, random_state=42)\n",
    "\n",
    "    # Perform UMAP transformation\n",
    "    embedding = reducer.fit_transform(waveforms)\n",
    "\n",
    "    # Create a DataFrame of the UMAP results\n",
    "    umap_df = pd.DataFrame(embedding, columns=['umap_1', 'umap_2'])\n",
    "\n",
    "    # Reset the index in sorted_df to make sure we can pull the correct spike_id and unit_id\n",
    "    sorted_df = sorted_df.drop_duplicates('spike_id').set_index('spike_id')\n",
    "\n",
    "    # Assign spike_id back to umap_df from the index of waveforms to ensure correct alignment\n",
    "    umap_df['spike_id'] = sorted_df.index\n",
    "\n",
    "    # Retrieve the unit_id for each spike_id and add it to umap_df\n",
    "    umap_df['unit_id'] = sorted_df['unit_id']\n",
    "    umap_df['unit_region'] = sorted_df['unit_region']\n",
    "\n",
    "    return umap_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_l_ratio(umap_df):\n",
    "    l_ratios = []\n",
    "\n",
    "    for (unit_id, unit_region), cluster in umap_df.groupby(['unit_id', 'unit_region']):\n",
    "        cluster_center = cluster[['umap_1', 'umap_2']].mean().values\n",
    "        other_data = umap_df[umap_df['unit_id'] != unit_id][['umap_1', 'umap_2']].values\n",
    "\n",
    "        # Calculate covariance matrix of the cluster\n",
    "        covariance_matrix = np.cov(cluster[['umap_1', 'umap_2']], rowvar=False)\n",
    "        # Regularize matrix to prevent issues with matrix inversion if covariance matrix is singular or near-singular\n",
    "        inv_cov_matrix = np.linalg.inv(covariance_matrix + np.eye(covariance_matrix.shape[0]) * 1e-5)\n",
    "\n",
    "        # Calculate Mahalanobis distances within the cluster\n",
    "        mahalanobis_distances = cluster[['umap_1', 'umap_2']].apply(\n",
    "            lambda row: mahalanobis(row.values, cluster_center, inv_cov_matrix), axis=1\n",
    "        )\n",
    "\n",
    "        # Chi-squared cumulative distribution function values for the distances\n",
    "        chi2_vals = chi2.cdf(mahalanobis_distances**2, df=2)  # 2 degrees of freedom for 2 features\n",
    "\n",
    "        # Calculate Mahalanobis distances for all non-cluster spikes to the cluster center\n",
    "        all_distances = [mahalanobis(point, cluster_center, inv_cov_matrix) for point in other_data]\n",
    "\n",
    "        # L-Ratio calculation\n",
    "        L_ratio = chi2_vals.sum() / len(all_distances)\n",
    "        \n",
    "        l_ratios.append({\n",
    "            'unit_id': unit_id,\n",
    "            'unit_region': unit_region,\n",
    "            'l_ratio': L_ratio\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(l_ratios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unit_id</th>\n",
       "      <th>fwhm_cv</th>\n",
       "      <th>auc_cv</th>\n",
       "      <th>max_amplitude_cv</th>\n",
       "      <th>euclidean_distance_cv</th>\n",
       "      <th>unit_region</th>\n",
       "      <th>l_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S01_Ch195_neg_Unit3_Feb02</td>\n",
       "      <td>1.085909</td>\n",
       "      <td>-0.803846</td>\n",
       "      <td>0.223294</td>\n",
       "      <td>0.090769</td>\n",
       "      <td>CLA</td>\n",
       "      <td>0.002575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S01_Ch195_pos_Unit2_Feb02</td>\n",
       "      <td>0.347622</td>\n",
       "      <td>3.463531</td>\n",
       "      <td>0.187287</td>\n",
       "      <td>0.264948</td>\n",
       "      <td>CLA</td>\n",
       "      <td>0.002741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S01_Ch196_neg_Unit1_Feb02</td>\n",
       "      <td>1.058625</td>\n",
       "      <td>-1.036876</td>\n",
       "      <td>0.235700</td>\n",
       "      <td>0.088132</td>\n",
       "      <td>CLA</td>\n",
       "      <td>0.002795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S01_Ch196_neg_Unit3_Feb02</td>\n",
       "      <td>0.436251</td>\n",
       "      <td>0.524794</td>\n",
       "      <td>0.177187</td>\n",
       "      <td>0.108910</td>\n",
       "      <td>CLA</td>\n",
       "      <td>0.003424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S01_Ch196_neg_Unit4_Feb02</td>\n",
       "      <td>1.537203</td>\n",
       "      <td>-0.474102</td>\n",
       "      <td>0.132667</td>\n",
       "      <td>0.055160</td>\n",
       "      <td>CLA</td>\n",
       "      <td>0.000935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>S05_Ch239_neg_Unit3_Jul11</td>\n",
       "      <td>0.403287</td>\n",
       "      <td>0.408167</td>\n",
       "      <td>0.180976</td>\n",
       "      <td>0.081559</td>\n",
       "      <td>AMY</td>\n",
       "      <td>0.004064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>S05_Ch240_neg_Unit1_Jul11</td>\n",
       "      <td>0.523054</td>\n",
       "      <td>0.597725</td>\n",
       "      <td>0.249160</td>\n",
       "      <td>0.127569</td>\n",
       "      <td>AMY</td>\n",
       "      <td>0.004394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>S05_Ch240_neg_Unit2_Jul12</td>\n",
       "      <td>0.786767</td>\n",
       "      <td>0.962331</td>\n",
       "      <td>0.211506</td>\n",
       "      <td>0.074270</td>\n",
       "      <td>AMY</td>\n",
       "      <td>0.004138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>S05_Ch240_neg_Unit2_Jul13</td>\n",
       "      <td>0.846109</td>\n",
       "      <td>0.957269</td>\n",
       "      <td>0.241092</td>\n",
       "      <td>0.117439</td>\n",
       "      <td>AMY</td>\n",
       "      <td>0.004216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>S05_Ch240_neg_Unit3_Jul13</td>\n",
       "      <td>0.167044</td>\n",
       "      <td>0.269675</td>\n",
       "      <td>0.102361</td>\n",
       "      <td>0.044542</td>\n",
       "      <td>AMY</td>\n",
       "      <td>0.002004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>122 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       unit_id   fwhm_cv    auc_cv  max_amplitude_cv  \\\n",
       "0    S01_Ch195_neg_Unit3_Feb02  1.085909 -0.803846          0.223294   \n",
       "1    S01_Ch195_pos_Unit2_Feb02  0.347622  3.463531          0.187287   \n",
       "2    S01_Ch196_neg_Unit1_Feb02  1.058625 -1.036876          0.235700   \n",
       "3    S01_Ch196_neg_Unit3_Feb02  0.436251  0.524794          0.177187   \n",
       "4    S01_Ch196_neg_Unit4_Feb02  1.537203 -0.474102          0.132667   \n",
       "..                         ...       ...       ...               ...   \n",
       "117  S05_Ch239_neg_Unit3_Jul11  0.403287  0.408167          0.180976   \n",
       "118  S05_Ch240_neg_Unit1_Jul11  0.523054  0.597725          0.249160   \n",
       "119  S05_Ch240_neg_Unit2_Jul12  0.786767  0.962331          0.211506   \n",
       "120  S05_Ch240_neg_Unit2_Jul13  0.846109  0.957269          0.241092   \n",
       "121  S05_Ch240_neg_Unit3_Jul13  0.167044  0.269675          0.102361   \n",
       "\n",
       "     euclidean_distance_cv unit_region   l_ratio  \n",
       "0                 0.090769         CLA  0.002575  \n",
       "1                 0.264948         CLA  0.002741  \n",
       "2                 0.088132         CLA  0.002795  \n",
       "3                 0.108910         CLA  0.003424  \n",
       "4                 0.055160         CLA  0.000935  \n",
       "..                     ...         ...       ...  \n",
       "117               0.081559         AMY  0.004064  \n",
       "118               0.127569         AMY  0.004394  \n",
       "119               0.074270         AMY  0.004138  \n",
       "120               0.117439         AMY  0.004216  \n",
       "121               0.044542         AMY  0.002004  \n",
       "\n",
       "[122 rows x 7 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unit_metrics = calculate_unit_metrics(sample_waveforms, mean_waveforms)\n",
    "umap_results = perform_umap(sample_waveforms)\n",
    "l_ratios = calculate_l_ratio(umap_results)\n",
    "final_df = unit_metrics.merge(l_ratios, on='unit_id')\n",
    "final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export for UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unit_id</th>\n",
       "      <th>fwhm_cv</th>\n",
       "      <th>auc_cv</th>\n",
       "      <th>max_amplitude_cv</th>\n",
       "      <th>euclidean_distance_cv</th>\n",
       "      <th>unit_region</th>\n",
       "      <th>l_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S01_Ch195_neg_Unit3_Feb02</td>\n",
       "      <td>1.085909</td>\n",
       "      <td>-0.803846</td>\n",
       "      <td>0.223294</td>\n",
       "      <td>0.090769</td>\n",
       "      <td>CLA</td>\n",
       "      <td>0.002575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S01_Ch195_pos_Unit2_Feb02</td>\n",
       "      <td>0.347622</td>\n",
       "      <td>3.463531</td>\n",
       "      <td>0.187287</td>\n",
       "      <td>0.264948</td>\n",
       "      <td>CLA</td>\n",
       "      <td>0.002741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S01_Ch196_neg_Unit1_Feb02</td>\n",
       "      <td>1.058625</td>\n",
       "      <td>-1.036876</td>\n",
       "      <td>0.235700</td>\n",
       "      <td>0.088132</td>\n",
       "      <td>CLA</td>\n",
       "      <td>0.002795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S01_Ch196_neg_Unit3_Feb02</td>\n",
       "      <td>0.436251</td>\n",
       "      <td>0.524794</td>\n",
       "      <td>0.177187</td>\n",
       "      <td>0.108910</td>\n",
       "      <td>CLA</td>\n",
       "      <td>0.003424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S01_Ch196_neg_Unit4_Feb02</td>\n",
       "      <td>1.537203</td>\n",
       "      <td>-0.474102</td>\n",
       "      <td>0.132667</td>\n",
       "      <td>0.055160</td>\n",
       "      <td>CLA</td>\n",
       "      <td>0.000935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>S05_Ch239_neg_Unit3_Jul11</td>\n",
       "      <td>0.403287</td>\n",
       "      <td>0.408167</td>\n",
       "      <td>0.180976</td>\n",
       "      <td>0.081559</td>\n",
       "      <td>AMY</td>\n",
       "      <td>0.004064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>S05_Ch240_neg_Unit1_Jul11</td>\n",
       "      <td>0.523054</td>\n",
       "      <td>0.597725</td>\n",
       "      <td>0.249160</td>\n",
       "      <td>0.127569</td>\n",
       "      <td>AMY</td>\n",
       "      <td>0.004394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>S05_Ch240_neg_Unit2_Jul12</td>\n",
       "      <td>0.786767</td>\n",
       "      <td>0.962331</td>\n",
       "      <td>0.211506</td>\n",
       "      <td>0.074270</td>\n",
       "      <td>AMY</td>\n",
       "      <td>0.004138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>S05_Ch240_neg_Unit2_Jul13</td>\n",
       "      <td>0.846109</td>\n",
       "      <td>0.957269</td>\n",
       "      <td>0.241092</td>\n",
       "      <td>0.117439</td>\n",
       "      <td>AMY</td>\n",
       "      <td>0.004216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>S05_Ch240_neg_Unit3_Jul13</td>\n",
       "      <td>0.167044</td>\n",
       "      <td>0.269675</td>\n",
       "      <td>0.102361</td>\n",
       "      <td>0.044542</td>\n",
       "      <td>AMY</td>\n",
       "      <td>0.002004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>122 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       unit_id   fwhm_cv    auc_cv  max_amplitude_cv  \\\n",
       "0    S01_Ch195_neg_Unit3_Feb02  1.085909 -0.803846          0.223294   \n",
       "1    S01_Ch195_pos_Unit2_Feb02  0.347622  3.463531          0.187287   \n",
       "2    S01_Ch196_neg_Unit1_Feb02  1.058625 -1.036876          0.235700   \n",
       "3    S01_Ch196_neg_Unit3_Feb02  0.436251  0.524794          0.177187   \n",
       "4    S01_Ch196_neg_Unit4_Feb02  1.537203 -0.474102          0.132667   \n",
       "..                         ...       ...       ...               ...   \n",
       "117  S05_Ch239_neg_Unit3_Jul11  0.403287  0.408167          0.180976   \n",
       "118  S05_Ch240_neg_Unit1_Jul11  0.523054  0.597725          0.249160   \n",
       "119  S05_Ch240_neg_Unit2_Jul12  0.786767  0.962331          0.211506   \n",
       "120  S05_Ch240_neg_Unit2_Jul13  0.846109  0.957269          0.241092   \n",
       "121  S05_Ch240_neg_Unit3_Jul13  0.167044  0.269675          0.102361   \n",
       "\n",
       "     euclidean_distance_cv unit_region   l_ratio  \n",
       "0                 0.090769         CLA  0.002575  \n",
       "1                 0.264948         CLA  0.002741  \n",
       "2                 0.088132         CLA  0.002795  \n",
       "3                 0.108910         CLA  0.003424  \n",
       "4                 0.055160         CLA  0.000935  \n",
       "..                     ...         ...       ...  \n",
       "117               0.081559         AMY  0.004064  \n",
       "118               0.127569         AMY  0.004394  \n",
       "119               0.074270         AMY  0.004138  \n",
       "120               0.117439         AMY  0.004216  \n",
       "121               0.044542         AMY  0.002004  \n",
       "\n",
       "[122 rows x 7 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.to_csv(output_path, index=False)\n",
    "final_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sandbox",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
